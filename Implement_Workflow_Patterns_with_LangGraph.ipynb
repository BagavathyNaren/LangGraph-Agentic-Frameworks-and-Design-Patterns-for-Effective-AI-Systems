{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce7e2d58-dc35-4987-bedd-42de57e44b22"
      },
      "source": [
        "#  Implement Workflow Patterns with LangGraph\n",
        "\n",
        "Estimated time needed: **45** minutes\n",
        "\n",
        "## Introduction\n",
        "In this lab, you'll master the three essential workflow patterns that transform individual AI models into sophisticated, coordinated systems. Through hands-on projects using LangGraph and LangChain, you'll build job application assistants, intelligent task routers, and multilingual processors that demonstrate real-world multi-agent coordination.\n",
        "These proven patterns - Sequential Agent Coordination, Intent-Based Routing, and Parallel Agent Execution - form the foundation of every enterprise AI system. By the end, you'll have the architectural knowledge to create AI applications that intelligently orchestrate multiple specialized agents to solve complex problems.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e508b2e-2a60-42ca-ab38-bc5ba75c7d0f"
      },
      "source": [
        "## __Table of Contents__\n",
        "\n",
        "<ol>\n",
        "    <li><a href=\"#Prompt-Chaining\">Prompt Chaining</a></li>\n",
        "    <li><a href=\"#Resume-Summary-Agent\">Resume Summary Agent</a></li>\n",
        "    <li><a href=\"#Generate-Cover-Letter-Agent\">Generate Cover Letter Agent</a></li>\n",
        "    <li><a href=\"#LangGraph-Workflow\">LangGraph Workflow</a></li>\n",
        "    <li><a href=\"#Initializing-the-LangGraph-Workflow\">Initializing the LangGraph Workflow</a></li>\n",
        "    <li><a href=\"#Workflow-Pattern:-Routing\">Workflow Pattern: Routing</a></li>\n",
        "    <li><a href=\"#Workflow-Pattern:-Parallelization\">Workflow Pattern: Parallelization</a></li>\n",
        "    </ol>\n",
        "\n",
        "<a href=\"#Exercises:-Building-a-Multi-Agent-Routing-System\">Exercises: Building a Multi-Agent Routing System</a>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dce203b4-6170-426f-b70f-461abf05021a"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "d041c1bb-c4bc-480b-befb-b8b7782ee93a"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain-openai==0.3.27\n",
        "!pip install langgraph==0.6.6\n",
        "!pip install pygraphviz==1.14\n",
        "\"\"\"\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "52f49234-d097-4416-8489-c4862696333b"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END,START\n",
        "from typing import TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import END, StateGraph\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "79be4492-84e6-4b48-b170-05b33ff5c8a9"
      },
      "outputs": [],
      "source": [
        "def print_workflow_info(workflow, app=None):\n",
        "    \"\"\"Prints comprehensive information about a LangGraph workflow.\"\"\"\n",
        "    print(\"WORKFLOW INFORMATION\")\n",
        "    print(\"====================\")\n",
        "    print(f\"Nodes: {workflow.nodes}\")\n",
        "    print(f\"Edges: {workflow.edges}\")\n",
        "\n",
        "\n",
        "    # Use getter method for finish points if available\n",
        "    try:\n",
        "        finish_points = workflow.finish_points\n",
        "        print(f\"Finish points: {finish_points}\")\n",
        "    except:\n",
        "        try:\n",
        "            # Alternative approaches\n",
        "            print(f\"Finish point: {workflow._finish_point}\")\n",
        "        except:\n",
        "            print(\"Finish points attribute not directly accessible\")\n",
        "\n",
        "    if app:\n",
        "        print(\"\\nWorkflow Visualization:\")\n",
        "        from IPython.display import display\n",
        "        display(app.get_graph().draw_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d4c7912-8d6a-4781-8345-dd475eb75154"
      },
      "source": [
        "\n",
        "Now we are going to instantiate the `ChatOpenAI` class with the `gpt-4o-mini` model. This instance, stored in the variable `llm`, will be used to handle all LLM-based interactions throughout our workflows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "d937a2f7-1a1e-4316-afb2-1d5f44742b77"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b77d5f09-43fc-4250-92ef-1e4450f9b4a0"
      },
      "source": [
        "### Prompt Chaining\n",
        "\n",
        "Prompt Chaining is a workflow design pattern where complex tasks are decomposed into a sequence of LLM (Large Language Model) calls. Each step depends on the output of the previous one, allowing for step-by-step refinement or evolution of the data being processed. This method mirrors how humans tackle multifaceted problems—by breaking them down into manageable steps.\n",
        "\n",
        "It leverages **function calling**, **sequential chaining** and or **AI Agents** , often implemented using frameworks such as **LangChain**, **LangGraph**, or even custom scripts. The key is modularity and clarity—each node (or step) has a specific role in the overall pipeline. Each link in the chain is a tool call or Agent the structure of which is something like the following:\n",
        "\n",
        "#### Typical Structure:\n",
        "- **Step 1:** Initial LLM prompt (for example, generate a draft)\n",
        "- **Step 2:** Refinement prompt (for example, improve style, tone)\n",
        "- **Step 3:** Evaluation or formatting (for example, convert to specific format or assess quality)\n",
        "\n",
        "This pattern also allows injecting **external tools** between steps (for example, validation, summarization, keyword extraction).\n",
        "\n",
        "---\n",
        "\n",
        "#### Use Cases:\n",
        "- Generating blog posts or marketing copy step-by-step (idea → outline → paragraph → polish)\n",
        "- Automated report generation (for example, extract → analyze → summarize)\n",
        "- Educational content creation (for example, topic → questions → answers → explanations)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36711bec-d4ab-4384-b312-8e1740b176ce"
      },
      "source": [
        "### Use Case: Prompt Chaining — Job Application Assistant\n",
        "\n",
        "In this workflow, we are going to build a simple **job application assistant** using the Prompt Chaining pattern. The goal is to help a user create a **personalized cover letter** from a given job description.\n",
        "\n",
        "We will break the task into two sequential steps:\n",
        "1. First, the LLM will read the **job description** and generate a **resume summary** tailored to that role.\n",
        "2. Then, using this summary, the LLM will generate a professional **cover letter** suitable for submitting with a job application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00e3415c-bf6b-40ee-8fa5-12606f475cf5"
      },
      "source": [
        "For this workflow, we need a structured way to manage the data passed between each step. To achieve this, we define a `ChainState` using `TypedDict`. This state will act as a shared container for all intermediate and final outputs.\n",
        "\n",
        "- First, we have `job_description`, which will store the input provided by the user, typically a job posting or role summary.\n",
        "- Then, we include `resume_summary`, which will hold the tailored summary of the applicant’s profile generated by the LLM based on the job description.\n",
        "- Finally, we have `cover_letter`, where the personalized cover letter will be stored after the second LLM call completes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ff472eac-5d54-4a44-9eeb-c8a890b6b43e"
      },
      "outputs": [],
      "source": [
        "class ChainState(TypedDict):\n",
        "    job_description: str\n",
        "    resume_summary: str\n",
        "    cover_letter: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29d765ea-5752-4fe3-831a-d99eed9aaf03"
      },
      "source": [
        "We can represent an instance of the ChainState class as a Python dictionary. In the Prompt Chaining pattern, here's how the state evolves:\n",
        "```python\n",
        "\n",
        "state = {\n",
        "    \"job_description\": \"\",\n",
        "    \"resume_summary\": \"\",\n",
        "    \"cover_letter\": \"\"\n",
        "}\n",
        "```\n",
        "```Initial State```: The workflow begins with a dictionary containing only the job description:\n",
        "\n",
        "```python\n",
        "state = {\n",
        "    \"job_description\": \"\"We are looking for a data scientist with experience in machine learning, NLP..\",\n",
        "    \"resume_summary\": \"\",\n",
        "    \"cover_letter\": \"\"\n",
        "}\n",
        "```\n",
        "\n",
        "The  next state is given by:\n",
        "```python\n",
        "state = {\n",
        "    \"job_description\": \"\"We are looking for a data scientist with experience in machine learning, NLP..\",\n",
        "    \"resume_summary\": \"Results-driven data scientist with expertise in machine learning...\",\n",
        "    \"cover_letter\": \"\"\n",
        "}\n",
        "```\n",
        "and so on.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ad8fdbf-313d-4030-a4dc-b53b30294da5"
      },
      "source": [
        "Now, let's see how to build a prompt chain using a series of LLM calls—as in, agents. We'll demonstrate the process, which is summarized in the following image. The input is a state variable containing the job description. This is first passed to the Resume Summary agent, which generates a summary of the resume and stores it under the key resume_summary. That output is then used as input for the Generate Cover Letter agent, which produces a cover letter and fills in the key cover_letter.\n",
        "![Screenshot 2025-04-24 at 12.03.31 PM.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/hseuyL5ddwU6cvKXrVGQnw/Screenshot%202025-04-24%20at%2012-03-31%E2%80%AFPM.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "803afe63-3804-46da-a9d4-ac5bf1da3a62"
      },
      "source": [
        "### Resume Summary Agent\n",
        "\n",
        "In LLM workflows, an \"agent\" is created through a prompt that gives the LLM specific instructions and persona. The generate_resume_summary node demonstrates this by transforming the LLM into a \"resume assistant\" through its prompt. This node receives the state containing the job description, processes it using the agent created by the prompt, and returns an updated state with the new resume summary.\n",
        "Nodes provide the workflow structure while prompts define agent capabilities. The state object serves as shared memory between nodes, allowing each agent to build upon previous work while using the same underlying LLM instance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "f08e05cc-ad72-4895-9627-419609290340"
      },
      "outputs": [],
      "source": [
        "def generate_resume_summary(state: ChainState) -> ChainState:\n",
        "    prompt = f\"\"\"\n",
        "You're a resume assistant. Read the following job description and summarize the key qualifications and experience the ideal candidate should have, phrased as if from the perspective of a strong applicant's resume summary.\n",
        "\n",
        "Job Description:\n",
        "{state['job_description']}\n",
        "\"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    return {**state, \"resume_summary\": response.content}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab98248e-8a09-471c-84e2-0c1bd0b70ff0"
      },
      "source": [
        "The agent starts with this initial state and passes it to the first node, generate_resume_summary. Inside that function, it can access the job description using ```state['job_description']```, which will serve as the input later on.\n",
        "\n",
        "When the function returns, it uses Python’s dictionary unpacking syntax: **state**. This means “create a new dictionary that includes all the key-value pairs from the original state dictionary, and then add or update specific keys.” In this case, it updates the \"resume_summary\" field with the newly generated content.\n",
        "The state varable would look like this:\n",
        "\n",
        "```python\n",
        "state = {\n",
        "    \"job_description\": \"\"We are looking for a data scientist with experience in machine learning, NLP..\",\n",
        "    \"resume_summary\": \"Results-driven data scientist with expertise in machine learning...\",\n",
        "    \"cover_letter\": \"\"\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60fb1c90-9582-4d20-b381-941cd6963386"
      },
      "source": [
        "### Generate Cover Letter Agent\n",
        "\n",
        "\n",
        "The ```generate_cover_letter``` node defines our second agent in the workflow. This function creates a specialized agent through its prompt This agent accesses both ```state['resume_summary']``` and ```state['job_description'] ```from the current state, leveraging both the output from the previous agent and the original input. The prompt transforms the LLM into a cover letter specialist that synthesizes these elements into a tailored application document. The agent's output is then added to the state dictionary under the ```cover_letter``` key, completing the workflow chain with a state object containing all three key elements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "1af64050-bc96-4bcb-8371-7215863c2c94"
      },
      "outputs": [],
      "source": [
        "def generate_cover_letter(state: ChainState) -> ChainState:\n",
        "    prompt = f\"\"\"\n",
        "You're a cover letter writing assistant. Using the resume summary below, write a professional and personalized cover letter for the following job.\n",
        "\n",
        "Resume Summary:\n",
        "{state['resume_summary']}\n",
        "\n",
        "Job Description:\n",
        "{state['job_description']}\n",
        "\"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    return {**state, \"cover_letter\": response.content}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f2be91c-60d9-4afb-9c3b-64b8713913de"
      },
      "source": [
        "## LangGraph Workflow\n",
        "### Initializing the LangGraph Workflow\n",
        "\n",
        "\n",
        "\n",
        "This line creates a new `StateGraph` instance and configures it with our `ChainState` definition. This crucial step establishes the workflow's foundation by specifying the structure of data that will flow through the nodes. The `StateGraph` uses the `ChainState` TypedDict to validate data types for each field (`job_description`, `resume_summary`, and `cover_letter`), ensuring proper information passing between nodes. This data contract enables LangGraph to manage state transitions efficiently as the workflow progresses from node to node.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ed08fda-5186-42b1-91a1-083422d414fb",
        "outputId": "62fdc1a6-029f-4ba3-cd09-83db14670d54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab599110>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow = StateGraph(ChainState)\n",
        "workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9e1adff-fec5-4dc0-b988-cba22bd686d8"
      },
      "source": [
        "We are adding two nodes to our workflow graph. Each node represents a distinct step in the prompt chaining process:\n",
        "\n",
        "- `\"generate_resume_summary\"` is the first node, which generates a tailored summary based on the job description.\n",
        "- `\"generate_cover_letter\"` is the second node, which uses that summary to create a personalized cover letter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "887d3434-9c56-4792-8771-a87e5418a367",
        "outputId": "9cfe9934-a60c-4ef4-e998-693c979574d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab599110>"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_node(\"generate_resume_summary\", generate_resume_summary)\n",
        "workflow.add_node(\"generate_cover_letter\", generate_cover_letter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94083ada-98cb-4065-bf07-f7f499dd1078"
      },
      "source": [
        "Setting the **entry point** of the workflow to `\"generate_resume_summary\"`. This means that when the workflow is executed, it will start with this node.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "186f6547-5134-44c4-89fa-69f568c56f89",
        "outputId": "ad26bae8-b92f-4fa2-d5dc-96dae77e908d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab599110>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.set_entry_point(\"generate_resume_summary\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe328df5-4805-452b-8cb4-c2555ca78c51"
      },
      "source": [
        "Now we are defining the **connection between two nodes** by adding an edge from `\"generate_resume_summary\"` to `\"generate_cover_letter\"`. This tells the workflow to pass the state from the first node to the second, forming a sequential chain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3080207-15b6-4c58-ac1e-e3644488dacc",
        "outputId": "b6c3e42e-6535-4016-efc9-5a5d7c6ec986"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab599110>"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_edge(\"generate_resume_summary\", \"generate_cover_letter\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e02f063-56eb-416b-94e1-4272a5358444"
      },
      "source": [
        "Now we are marking `\"generate_cover_letter\"` as the final node, indicating where the workflow should end.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4355138d-76c4-4995-ad99-1d93ed8a9a68",
        "outputId": "51f196e6-ea7f-4a60-9445-ce3f1f81801d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab599110>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.set_finish_point(\"generate_cover_letter\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c74e5c8a-152b-4c6f-90e1-c06f41224cde",
        "outputId": "cd4e2d4f-3df8-43f4-eea0-0f4a826d9d79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WORKFLOW INFORMATION\n",
            "====================\n",
            "Nodes: {'generate_resume_summary': StateNodeSpec(runnable=generate_resume_summary(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class '__main__.ChainState'>, retry_policy=None, cache_policy=None, ends=(), defer=False), 'generate_cover_letter': StateNodeSpec(runnable=generate_cover_letter(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class '__main__.ChainState'>, retry_policy=None, cache_policy=None, ends=(), defer=False)}\n",
            "Edges: {('generate_resume_summary', 'generate_cover_letter'), ('generate_cover_letter', '__end__'), ('__start__', 'generate_resume_summary')}\n",
            "Finish points attribute not directly accessible\n"
          ]
        }
      ],
      "source": [
        "print_workflow_info(workflow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b12fcdf2-5f9d-4689-92b4-7d819cdef883"
      },
      "source": [
        "Now we are compiling the workflow into an executable app, which prepares it for running with input data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "5dfda32b-69c6-41ce-8bcf-cbf0d6599772"
      },
      "outputs": [],
      "source": [
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "3f36685c-11c5-4e12-8ede-db6ede80cff8",
        "outputId": "c7771656-b9cc-4ab1-8895-cc1b29748c97"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAFNCAIAAAC8CgWdAAAQAElEQVR4nOydBXwUx9vHZ+8u7k4ESSBYkECDFg9WCsUdihcotHgLxe3FKS1SCilOCBKKN7hDcNeGBAgRIEJcTvZ97jYcl+TucuHPTsnt8y2fdG92Z3Z27rfPPPPM7pyEZVmCIMaLhCCIUYMSR4wclDhi5KDEESMHJY4YOShxxMhBiRfkyY2UyLsZKQlSmZzIpVoiqmIxI5cXTGdEDEOIQlEonSGFo7LKg1m2wLEiEQMJBVLhyMIphfNKTBgTM8baXlK2iqVffXuCaMBgXJzj0sGEpzfSMtLkIEqJCRGDaEzFRMEUPpKREFZWKFFElO2oKJReUOKsMk15MFugcEhU7lYULBZuG4Yw+U7EqorRQCwhUplClqOQ5iq/T3MrUfka1k27uhIEJQ5c2P/m/qVUhmFcy5jVbe3oWcGSlGRev8y6EpYYH5WjkBPf2laBvUoRYSN0iW+cFZWTrfBvYlu/nQsxLm6eSrxx8h3cukPn+RABI1yJv3ubtW1BTOmKZh1HlCbGy9HNcRF3MtoMcKtQ04YIEoFKPDdHvm5yVPthpcpVtSbGTkpC9tb5r4bM9bawFhPhIUSJv4nJ3L08dtSyCkRI/DEpoll35yp1BRdvERHhsWd5bOfRHkRgjFxS4dTOBCI8BCfxoGmRpStbeHiX7LDJx1G1vs26Kc+IwBCWxE+EvJbLFB2GeRJB0ry7m1jCHFwXQ4SEsCT++GpanTaORMC06O3y8kkWERICkvjpPfEwbVm7uaAl7l3VxsSUORQkIEMuIIlH3M7wqmhBBE/FL6xinmUTwSAgiedksIE9ac9mt2rVKiam2Cbz2bNn7du3J/zQrFspaQ6bnCgUlQtF4uH/vBWbEMpzH3FxccnJyaT4PHz4kPCJiRlz/eg7IgyEIvG4yBxzC770DdNnwcHBffr0+fLLL/v167dq1Sq5XH79+vUOHTrA3o4dO06YMIGobPOiRYu6devWsGFDOGzPnj1c9oiIiICAgAsXLrRt27Z3795r166dPXt2fHw8JG7fvp3wgLWdJCkulwgDoTwvnpEqM7fh634OCQnZsGHD2LFjQeJnzpxZvXq1lZXVoEGDVqxYAYn79+/39FSGKZctWxYbGzt16lSGYZ4/fw5yd3d3hywmJiawNygoqH///v7+/n5+frm5uceOHTt06BDhB0tbUcpbGREGQpG4QgZeCl8Sv3nzZtWqVTnvuXPnznXq1MnMzCx82IIFCzIyMjw8lBOrYKEPHDhw6dIlkDijfJuC1K9fv2/fvoQK5uaSZKmUCAOhSFz5JgLhi5o1a65cuXLOnDm1atVq0qSJl5eX1sPAnwF7f/HixRcvXnApnHXnqFKlCqEHyzL8tcfnhVAkLhaTXClfD5yBFw6eydmzZ8GHlkgkEEX58ccfXVzyPYCuUCjGjBkDHsjo0aPBhNvY2AwZMkTzADMzM0KLnGwFI5hYmlAkbmYlTk/my/sUiUSdVURGRl69enXdunXp6em//vqr5jGPHz9+8ODBmjVr6taty6WkpaW5uv43756lv5OZmQvFigvlXi5Vxiw7Q074AcaFEC2BDR8fn169ekFU5MmTJwWOefdOGaRTazpSBfmPSE+V2bubEGEgFIk3/MZJzlsIISwsbNKkSefOnUtJSYHY36lTp8A7h/Ry5crB3+PHj9+/fx/UDz7M1q1bU1NTIZyyZMkSGF9C4FxrgWXKlElISIDgjNpr/7TIckjNxnZEGAhF4mKxWGLKHA+OIzwwbdo0UPD48eMDAwPnzp3btGlTiAxCOow7ITQOcW4YjJYqVWrevHn37t1r0aLFuHHjRo0aBQFykD78LVxgo0aNIHo4ceLEo0ePkk/NlaPKp8a9yhv/604cAnrr59D62OinmSOXCOtln8IETXtm62zaY6wxv7GqiYCeUWk/zANu56hHaUTAZGVKszNY4eibCG01LHcf8xPb3g6br/1ddHB8BwwYoHUXw+js7jp16gRTmIQfoOTbt29r3WVnZweuv9Zd4OHoeoprx6KXDh7CeklZcK8nr/35WbWGto06alk1RS6Xa52VBLKysiwstD+IC9Pv5ubmhB+gPlArrbukUik3818YCLGbmpoWTr93MelsaNLo5cJy1QQn8aTXOTsWRY8S2NfMsXpCROv+rr7+tkRICO71ZEc3s9ot7f6cLLi3dNdPjahY21Jo+iaCXSooJiJz3x8CWkplzaSINv3dytcQ4oJYwl3w7dqxhCth7+p95VCnlRMxXh5cfXdmZ0KlOlYte7kTQSLoZTsTXmWFrooxsxJ3HFHKwcXYXuvMzc3duTQmLUneup9bBX+BLmhIcGVaIHTlq/jn2VZ2osoBNsaxPu2NE0n3w1PSk+XOHiY9J5QlwgYlnsffa6LfRufKpKyZBWNhKzYzE1vZihVahuMfnjznlsfP+6P+qPFXzfsjGVZj7fsCRxbeKLydV4NC3xgrl+dms1np8oxUuTRHIRITJ3fT7mPLEAQlXoD4F1l3L6Qkxmanv1OApKQ5hRtH4+UK5v2nPGmqGlP1scBUEfeR06tCoRCJPtw573N/yAKHKdi8X4YoeKuokgp/ZSKRQmwqMrMQO3ua+tW3LVNJKM+fGAJKnDYNGjQ4e/as1qkZhA/w56xoI5PJJBJsdnpgW1MFvBSiekuIILRAiVMFTTh9sLmpoufZKYQnUOJUQStOH2xuqqDE6YPNTRWUOH2wuamCvjh9UOJUQStOH2xuqqDE6YPNTRWUOH2wuamCEqcPNjdVUOL0weamCkqcPtjcVEGJ0webmyoocfpgc1MFp37ogxKnClpx+mBzUwUlTh9sbqqgxOmDzU0VlDh9sLmpgsNN+qDEqYJWnD7Y3FQBE25jI9zlBf8TUOJUUSgU3A9wItRAiVMFvBTwVQhCEZQ4VVDi9EGJU0UsFuv6eSqEJ1DiVEErTh+UOFVQ4vRBiVMFJU4flDhVUOL0QYlTBSVOH5Q4VTCiQh+UOFXQitMHJU4VlDh9UOJUQYnTByVOFZQ4fVDiVEGJ0wclThWMqNAHJU4VtOL0wV9PpsGECRNOnTrFqH7FHhpcJBLBNsg9PDycIDyDv3FKg9GjR5ctW1akAnwV0LdCoShdujRB+AclTgNvb+8GDRpodpgmJiY9evQgCP+gxCnRr18/Ly8v9Ud3d/fOnTsThH9Q4pTw9PRs2rQptw1eeJcuXXC1CTqgxOkxYMCAMmXKwIaHh0fXrl0JQoWiIyovn2b8ezMtJ5sUURBD1CXBJnzW+EhYHUeqP3J/Rcq/yk/5Sib5UsQiIlcULCR/TRhV3CLfKQjJf1JlDUWaBxWuFZclX3qBK9E4skD5WmoFJ2OYqMiIiMhIH+/ywIcTFD74fQMWeXZlsoiw2hqEUZ1SV02INkQMq8ifhWHyFFLgW3i/t1ATFbwQhiW624UrT0cJReSFztCM9almVaG6LdFLERL/a0ZETiYxMRNJcwq0H5ydyVdVVUPnfWRUTaLQ2M1++IIKiYlRxdEgyMAy0MaQrWAr5zteJGEUsrzjNYrXOIBRFvDh7Hn1UX57msdANoUiXy5F/lopy2A/fMe6UJ0u79YsEuUFKs+ad4H5W7FAhVXCFeW7EF0VUNZTlO8C35+LLVyynnrmO52qWUWivFbSrkLuntB3H+oTKjStSoHaC1c2rF7DARKX58JfMmxeBaIbfd/fn5MjnD0lrb8tRxDkc+Xc369ePsgeuUSnynVKfP3UCC9f80advQiCfN7cv/jmzrnUEQu1q1z7cPPyoTcKOUF9IyWCal+6got1IiRW617tcauX/2ab22BICykx2DqYxkdJte7SbsWlmQpS1CgHQT4fJBJRbpZ2l1u7qYaoHKvQHldCkM8QmYKVy4sjcQQpYShI4Qgph3aJi0QMPmOLlCDEYkZiot3v0C5xmFXROjGGIJ8n4KXIpOioIIIEJY4YA4yIYUQ6HrzRmiqWiPAZRKREwRIdj8JoF7JchnFxpGTBMKQ4w00EKWmwuh5oRIkjxoCWh9nfgxJHjAHQt46ZHx0SZzAmjpQoWO41F21oH24q38IgOL2JlBzYfO9waaJd4qqjjcGSz54z+cg/+wli7IhEjEhHmNvIo99PnjwkiABgdb/k+cmGm8nJSQsWznjw8G6Z0uU6duz+6tXL8xdOb964B3bJZLK/NqwJv3LhzZv4atX8O3fsUb9+I0iPino2eGjPNas3BwdvvHDxjIuLa/Nmrb8b9oNYLIa9SUmJa/5Yfv/Bnezs7Dp1Gnzbb2jp0mUhPXRvSPCOjePGTpk566dOnXr8MGoilHPg4J6bt67Fx8eWK+vTrl2njt90gyObBwbA3yVL5/6x9teD+8/AdtjRgwcOhkZFRXh7V2jRvHXXLr2ZooYdHTsHwqnPXTh19+6t/ftO2drYPnhwd/OWdY8fP7Czd2hQv/GAb7+zsrKCI9PS0zZuWnsl/ELyu6RKFau2bPnV1+06QfqUqWPh74L5K7gCjx49tHDxrMMHz1laWkInAxWAQpYsmwtXXbmS36yZi/bt3w3l29ratWndfsTwMVwNdZ1UD/zV5+99u7ZuC1q8cNXU6eMSExPKlvWeMG7qu3fJIACZXFYnoMH4cb/Y2ztA4Zcvnz91+ujde7dSU1OqVK7Wv//QWv7KLyUyMmLIsF5Qh6XL58GRVlbWZqZmixetUld++oyJiUkJa1ZtIobB6HardVhxpthuyuKlc15GP1+yeM28ucuvXLkI/0Tve47fVy7eExrcuVPP4O0HmzYJnDn7p7PnThLVomfwd9nyeYGBbY+FXZ46Zd6u3dtOnzlOlE/VyMdNGH77zo1xY3/ZELTTwd7x+1EDYmJfwS5TU9PMzIwDB/ZMmTwH7hZIWb1m2bVrl8f8+PPCBb+Dvn/7fVH4lYuQHnZE+XfSxOmcvk+cDFu0eHZF38rB2w4MHTIKqrRqzbIirwsqeejI3xUqVFqyeLWlheWrmOiJP32fnZO9auXGubOXRkb+O278d9xis4sXz3744O7YsVM2bdhTpUq1X1csAF3qL1wikcA9DP927/xn7ZqtsDFm3DCFQn7owNmZMxZCa1xRXYiek+r7RnirD7RJenrapi1/Ll28BtpWKpX+38IZ/4QdCFofsn3r/nv3b+/ctRUOA9s0f8G0nJycyT/P/r/5K8qUKTd12jiwXOT9V79lW1DPHv0njJ/Wrm3HGzevcru4jGAQW7f6mhgMhFPYYvni4NiwomKIPCXlXXj4hR7d+1etUs3JyRkqDQaV2wVXePTYoT69B37ToaudrV27rzoGtmi7Zet6dd6mTVo2a9oSrrlmzdoe7p5Pnz6CxHv3br98+fyXKXPr1W3o6Og0csRYWzv70NBgolr+AZqgV68BLQPbenkpV96ZPn3BkiVrateqAxYC7HelilWuXrtUuJJHjuyrUaPW2DGTHRwc4eBBA0bs27cLOh/9lwanAwMGfUXAF/VAASdO/GMiMQGdwRdWrpzPxAnTnDkKzgAAEABJREFU/414Al0QHHnn7s0mTQLrBNR3dXWDvmj1qk1OTi6kKHJzc0ePmmhnZw+20Me7AtjOQQNHgEGFawHz9izyXzhGz0n1wF99AJA19CTQr1pYWNSr+2VcXAz0q25upeDL8q/5xbNnT+EYc3PzoHUhE8ZPhbzwb8TwsVlZWXADkLy1bgjUrXu3vlUq+zVv3hpOAfaeK5y7tBYt2hCDYUTKf1rR9TAtTOAXQ+LclVerVpP7aG1tXbt2XTDqsA2ShVaDzkt9MDQB3PEpqSncx4oVq6h3WVvbgHmADWgIED0IMe8CGAZywXemPhL60A+nZ9m9e0OuXL0YHf2CS3B39ySFrghs0rf9h6lTatWqA4nQh0LHQvQCvbx6+8GDO5Ur+4ECuI+lSrl7eHhBIXCXVq/uD3YO7vaaNWqDZ1VJ47r04OlZmjNpgIWlpZOjs3qXlaUV1xp6TqqnZP7qwwE+IbcB6gSrAeLOy2Vh+fpNPLcN/W3QX6ugNwZ/hksBf0ZdQkXfvCpBz9wy8Cu4k7t17QMfz58/9WXDpuATEoNhCM9TP2lpqfAXPCp1Clg+boNrlB/GDCmQJTkpkVvUT6RtJAy5wE5wzrQazr3jgEbhNkCmk38ZI5XmDhs62t8/wMbapvC5iMo4QYEwJIB/+apRlBXXPBdXscdPHhaoWLKqh/35p1ngPoEpAmFZW1l37twT7qgiFy4scPm6WkPXSfXAX304NIcxWoc0r1/Hjxk3tHatutOn/l/VqtXhmFZt6mseYGpmpt5u/3UXcPrBF4WbCqwVZCHFgdUd5P40EjczM4e/0txcdQoMcbgNJ2dl5wi9FZgHzSyurqWSkhJ0FQjeDvSA8+f9qpkoFokLH/n038cwCFu6ZM0XtetyKSAIF2fXAodBpwnGBty7Jvlttod78RbScHRyBusIfbdmop2t0r6C1enXd3DfPoPu378DQ+2t2/6CTqlH934FSpAriv1DKHpOqgf+6mMgZ84eB8sCjjh8lSS//S5M+fK+MGD455/9vr6VoR+oV+9LUizYYs5uKpdTK87MDxfriHr+DDxFohRZ+s2bV93c3GHby7OMmepm5YbSRGU4WZYFwSXpNqDly1cEvw1uA0+PPAnGxsXY2zkUPhI6Yvir1vTz55Hwz7tcea1lQpBBXQ0w6uBBgp9KikN5H99jxw9D1682b3A6GBKA33XyZBiMNOBeAjnCv4iIJ3D7wQGmJqbvUj58u2pv6n8/qZ4svNbHQCCKYmNjy+kb4GIMeoDahuzcArE4cFqKu2wvqzuoomN2U6Q3DFMIECKMTiC0BB0N6HvFbwvU3jBIeeCA4TC+hBEk3NNwnRAcWPHbQv0FgkmuW7fh0qVzobMDEUMXNmJk/7CwA4WPBI8QmgOG8KlpqTBCXblqCQxi4l/HEWXfYgaByOvXw2/dvg7xh2FDRl+8eAZmgsC3gcrMmTtl/MQRuRo9jyF069YXskMoBoa8II4/1/0Occ/IqAiJWAKXP2vOz2AyITJw7NjhfyMeV6/mD1nAOEE/A2Ey2L5+40qRw0TDT6onC6/1MRAfH19wwSFKC41/5eolsHownHjz3k0vTIvmbRIT34KXAlonnw4di0zI2OIuMvHTxBkQ4+z/bWcwOa1atQO//NGj+9yuXj2/BQsaHLIJLhLS/arWmDBhWpEFQtAUWmfOvCkPH96DXgLCul269Cp8GIzip/4yD77Ojp1agC80dcpciKdCVHXAoG4Qle/bZzDEhiHAsiP4EFiydWu3bw/eCBLJzs6CakB800zDHTQE6P3/CtoZErJ5+Mh+cEfBKBCCkhCIhF1zZi1ZuXoJNxLw9i4PAYSv2n4D25069oAjvxvRFyKhEIzv12cwxKGL9RNLek6qC4ia81cfAwls0ebFi0iwbhCvBLsDYwMw0sE7NsHIrbC/RFTW8Isv6r198xpqS4oLo3OGQ/uahpvnPgeJdx1blhgM2FqwMSA47iPML4AhmTtnKUEQw4AetXvPryC+yU1RFYvDQdFpSdJh830K7/pks5swMQax8JEjx9WoXgus740bVwoMFhFEF/HxcTGx0Xv/DgF39+O8FOWS3TqmfnQMN8VMcd9rmzlz0ZKlc9YHrXr79nXZMt4zpy+EvomUBDp800zXrp9/ntXoy2bkcwW6yvv3bmvdBbO8MF9GSggnT4UF/bUaHLBZMxYxn/pJbt2Oipx0HVeOCIC4+FhduxzsHSEiQT5XYDCXK9U+XLa0sFRPFQmBw0Gv0pOlQ+d5F96l21ERzGsR7qU8SMkEZg8IooJVsApc0xARJrpebGOM4o0IRCgwYiIq1mNYyhl/XLcTKUEodL4ToWsCHzLgclhIiYFliylx1cq0BEGMAO0SF4sZvh4/QxAeYIr7erJczrK4piFSclAGDYs1u4kgRgNKHDFytEvc1ELMytAbR0oMElPGzELHu/ZaUy2sSHY2ShwpMWSm5pjpWFdGu8Sb93DOSseoIVJiyExlawc6at2lXeJ2ThalvE23L9D36hSCfCbsWBJh72ZS0V/7ohSMnjme8KNvb51Mcfex9PS1sLA0JUXBkCJWs1WukKta7FzPkXm78o4qCgMPU729qmc3d1JDC1OtoGfgQzyMenH3oq6ZYQz9IUh1mfobnM07gDX4eSM2bxk0Q/pvgxuL0be8vdYaGEquTBr7JCPmWZZvLesWPUrpOozRP40ZHvb2UXh6dqZcLiWfpIIGXsMnkm6xjioGxSjQ4EM/eSXzii3GfVucCvBV3WIUKzIh5hYin5pWzbroW0aBwZl6yjRs2PD06dPFfS0a+WgwLk4bmUxW3EVCkP8FbGuqQJ+pUCi41aUROqDEqYImnD7Y3FSRSqXqdV8ROqDEqYJWnD7Y3FRBidMHm5sqKHH6YHNTBX1x+qDEqYJWnD7Y3FRBidMHm5sqKHH6YHNTBSVOH2xuquBwkz4ocarI5XK04pTB5qYKOCr4DBZlUOJUQV+cPtjcVEFfnD4ocaqgFacPNjdVUOL0weamCkqcPtjcVEGJ0webmyo43KQPSpwqaMXpg81NFTMzM0dHR4JQBCVOldzc3MTERIJQBCVOFfBSwFchCEVQ4lRBidMHJU4VsVgsl+NvE1AFJU4VtOL0QYlTBSVOH5Q4VVDi9EGJUwUlTh+UOFVQ4vRBiVMFIyr0QYlTBa04fVDiVEGJ0wclThWUOH1Q4lRBidMHJU4VlDh9UOJUwYgKfVDiVEErTh/89WQaDBo06NatWyKRiGE+NDh8vH79OkF4RkQQ/hkzZoyLiwsncdF7vLy8CMI/KHEa+Pv716hRQ6FQaCa2bt2aIPyDEqfEkCFDXF1d1R89PT179uxJEP5BiVOiatWq9erV47bBnDdq1MjJyYkg/IMSp8fAgQPBI4cNd3f3vn37EoQKlIKGsc8yM9MUjIiBbYZATIHJ28GwhM3bVm0xmrngg0KVyCj3Kv992J0vozKdO0ZXesHC3x+m3KuRRSOfdgruyzurllppuyjXJgE9rl69WrdW3awEu2cJGQVbQ/fp1YkfTqh5CR+qk680Le2mcXzhBtdFgassuKvQVb+vNKv66rTukZtbSrx8LQn/8B40PLwh5uWjLDgJqyCFT/Xhm2OUB3AfdLVMvq8qv97VX0FhfeR9zQXK1Cdjoq0AHfuY/BdVjGJ180kK+dgCdcqy+LXSn0MkUZ7Iw9u048gyhE/4lfj5fW8ehKcGtHKuFGBPECQ/z+4lhR9OKlvZ4qsBnoQ3eJT4vrXRCa9yek6qQBBENzuXRljbiXtN9Cb8wONwMzYip0UfHu9OxDjoObFCUpxcnsvXozt8STw87A04Wy6eFgRBikJiRk7teU34ga+ISuY7FuaqCYIYgFgszkrhy2HmS+IwVy3PxQe8EIOQyViZvKRJHEEMh2V5DOyhxJH/HrFEJJZ82rmAD/AlcZjHFIn4qjRiZCjkLKsgPMGbL86CO46+OGIo/Hkq6Kgg/z2M8jmkkuaoIIjhQIfPX5/Pl8QZhjDoiiOGIRaXwOGm8iEzBn1xxCAUMlYuK2lWXBnoVKAZRwyCkYAhR18cMV4gaCgvebObaMERgwETLuZtFoWvJ6UYFPnnyqzZP0+c9D35nIBoCn9xcb4krnyTjRgDf+/btWDRTCI8Zs+ZfOSf/dx2VNSzXn3aE95QLqEkLmlW3Gh48uQhESSaF/7kKb+NIJcrSl5E5SNQKBS//b7owsUzpiamgYFtq/nVnDJ1bOjuo46OTjKZ7K8Na8KvXHjzJr5aNf/OHXvUr9+Iy9WpS8tBA0ekpLzbvGWdhYVFnYAGo0dNdHJyJspHNLXnioyMGDKs14L5K5Yun2dv7xC0bkd6evruPduuXrv8/PkzJ0fnhg2bDh400tzcfOz47+7cuQlZjh07/OfabRV9Kz94cBdO9PjxAzt7hwb1Gw/49jsrK6siL+3y5fO/rVz09u2bCuUrdurU46u233DpFy+ehdJevIyys7OvUKHSmB9+dnMrFfTX6r/37dy396SJiQl3WMjOLXAh+/8+ZWlpGXb04IGDoVFREd7eFVo0b921S29uXrBj58Bv+w09d+HU3bu39u87ZWtjSwwgKSlxzR/L7z+4k52dXadOAyihdOmykN48MAD+Llk694+1v3bp3GvL1iAu8fuR47p366srV+jekOAdG8eNnTJz1k9wmT+MmkgMgxExIt6MLW++ePG7nd17th88tPeH0ZPWrt1mYWEJXypRrW0Jf39fuXhPaHDnTj2Dtx9s2iRw5uyfzp47yeUCHezcuQUO2/f3yc0bQ+/dv71p85/cLl25OOls2RbUs0f/CeOnwfbev+G72QQf/2/+iuHDx5w5exyUB+krlq+rUqVa69Zfnz55HfT9KiZ64k/fZ+dkr1q5ce7spZGR/44b/12RK82CvqfPnDhk8KiFC35v1Kj54iVzTpwMg/TrN67MmDUJCt8VcmTm9IWvX8et+H0hpDdv1jozM/Pq1UvqEs5fOA23E+gbMi5aPBtqErztwNAho+DqVq1Zpm6HQ0f+hvtkyeLVlhYGLd4gl8vHTRh++86NcWN/2RC008He8ftRA2JiX8GusCMX4e+kidMP7j8DFqRXz2/h3oNGAH3ryWVqapqZmXHgwJ4pk+eAQSGGo5zdJDzBo6NSXJUfPXaoSeMWzZq2tLO169tnkOV765iTkwO7+vQe+E2HrrCr3VcdA1u03bJ1vTqjp2fpfn0H21jbgPEGK/706SP9uTizVyegPnxhVSr7wXaP7v3AlsOpa/kHNG7UHER29dqlwjU8ceIfE4kJiLtMmXLlyvlMnDD934gn0O3ov66Nm9bCdbVq+RWcsX+/IXAjgQ4gfcPGPyC9W9c+YML9/Gp8P3J8ePiFx08eli/v6+HhBbLmsicmJjx8eK9FizawfeTIvho1ao0dM9nBwbF2rTqDBozYt29XcnISd1G2tnZgOAO+qCeRGNQ537t3++XL579MmVuvbkPoKgotx7QAAA+kSURBVEeOGGtrZx8aGvzRuaAOYNd79RrQMrCtl1exlo5g+HtGhbfhJmEUxRkjg5fy/HkkfNPqlCaNA7kNkGxubi5oV73Lv+YX4GykpKZwHytWrKLeZWNjm5GRblAu3w+5wAReu3555PfftmpTH7rjXbu3cbopwIMHdypX9gNFch9LlXIHLd69d4vova5nkf9WVt1IHCOGj4G7jij9pXzplSpWhb/gAsFfuB/OXzjFLbZ/7vwpcMAafdkMigLfQPOKatWqA4nqCnAlGA70eHDhcKtwH0Fk0ER37t78H3NVruRHigkjIvy9BcmbL84autISB3TNEDaytPzg16qVlJ6eBn9/GDOkQJbkpEQwz4Rof0hNTy7OyJmamakT161fCQYSXBQQEOcNq4MJBcoEK8v5qZoFEt2AVQMVmpmZFyoqHfoZzXTwQ4iyHZQGvmXgV5u3rL956xoY/gsXTjdu3ALqDEVJpVLw3zgX7kMF3t+N4CeQ4gCXAwUWuBwYnPyPuYpbDcI9hmX0L7bB2A7+QtupU5KT86Tj5KxcB3DC+KngkGhmcXUtpadAPbmSkhI0U+DWOngoFByG9l935lK426Mwjk7O1av7g2+qmWhnq28VJDMzMxgncB2LJtz1ZmdnqVMyVOKGwS78hV4e3JWLF89ABwVeLzjxXBa4DVq3+rpJk0DNojzcP3KdcvDroH+YP+9XzUSxSMxHLv3w+tDe5yJxsFKurm4Q0FCnXLx0ltvw8ixjprK44ChzKWC3VCZf36BKT66k/D4I3FdZWVnOznkrI4N7c+nyOa1llvfxPXb8cM0atUXvx//gXOl3OsVicaVKVaFzV6esD1oFpxj1/fhKFatAfEadzm37lPflPsJ44NChvWXL+oCHrfYKypevmJaepr4iqHlcXAy0G/kooDS4cLjnPT3ybpLYuBh7Owc+chUFj/OEvHlAxb8vGzZoAgK6dj0chAjRlbS0VC4dRDlwwHAYKcJAB8QBUREIa6z4baH+0gzPBR0rDB//CTsAYQEIPi5eOqd6NX84e0aG0qxCJ/Do0X3wGeAO6datL3gdEMQAnyE6+sWf634fPLRnZFSE/pp07NDt2rXLO3dtvXX7+v4De3aEbPb2Lg/pEOqBoWpo6I7UtFTYBWE4kLJvhUpcrmbNWsW/jgsLO9C8eWu4T7jEYUNGg2kHJwqqAdc1Z+6U8RNHwNWRj+KL2nXr1m24dOnc16/j4cL37d89YmR/OCNRdT4uLq7Xr4dDxSBkBLcxjHovXDgDV60n10dTMl9PZklxKw0xZrAHP/08GsyDv38AeA4QX5NIlAE+CFqB8QgO2XTz5lUrK2u/qjUmTJhWZIGG55o+9f9Wr1k2cFA3cAYgsgFnh5hd564tN28K7fB1Fxi5Tvpp1KKFKyFY8VfQzpCQzcNH9oOoAgwWIawGITz91WjTpn1qWgpEIeGegV7+u2E/QHiHKH8l4uu3CW927t4K9wwMAAK+qD9s6Gh1LmgEMPNPnj768Yef1IngJq1bu3178Ea4u8DJgSuaN3e5mcagorjA5ABE2efMmwJBG4htt2z5VZcuvbhdffsMhlgQRJZ2BB+qX68R3PYQ+oTvaOCA7/Tk+jh4dVT4WtPwRPDrpzfS+88ob3gWMI0wRwMGlfsI8x3bt284eOAMQYyd4IWRLp6mXUbz8uNHn9EEPmj6uxF9YYYMur9Tp49B5O6bb7oRRAAIZR0V6AFTUpKPHTu0Pmili4sbuKowAURKAlOmjr1/77bWXe3adYLJEUKXz60+/y08rqPyEd7VmB9/JiWQieOn5Uq1j/kMnEv/tHxu9SkSsUgkKXFv/SiKP9wsuXBPfX0+fG71KRK5QoFrGiLIR4ISR/57lC+24evJiBEjL4mvJ+OLm4jhiHh8lpbH1bAYlDliIIqSGBdXGM37yQj/lMj1xRHEcOQyYbyejCB8gBJHjBzehptiIin2+02IQBGbEAlvxpavgu0cxfg7KIiBsHJi7WhC+IGvh2kDWjkr5GxcZCpBEL3kAtlsYM+PfD2vSHh8Xtzbz/zMrjcEQfQSuuKlhw9fJpzw99YPx+1zyeGHEysF2Aa0diUIkp9bp988upJatb5t4448yoNfiQNnQ+MeX8+Q5RJWYdBcEEN4njJi//unCxiYFvtP6/CpGvmjy4EWUAYkTEg5P8s2/T0In/AucTVvX+Ua4haJGGLIOJVhiq45o/q9oQJHFfhWuMcM9M/Eqn61iC3uifIfwSjXTlL+ISNHjPh95W8mJvneKVb+LBKj7yzKanP5dRSv5xoK52NY5X/qkonOgovYKyIiBVHorrPuK5LLHT1M1SsL8Aq9uLiLFwYRlUS/fuDqaSGR4IwEJbChqQKmXi6Xo75pgm1NFalUql41HKEDSpwqMpkMTThlsLmpglacPihxqqDE6YMSpwo6KvTB5qYKSpw+2NxUQYnTB5ubKihx+mBzUwUlTh9sbqqgxOmDzU0VkDgGDSmDEqcKWnH6YHNTBSVOH2xuqqDE6YPNTRWUOH2wuamCEqcPNjdVUOL0weamCkqcPtjcVEGJ0webmyoocfpgc1MFJU4fbG6qmJqaOjk5EYQiKHGq5OTkJCYmEoQiKHGqgJcCvgpBKIISpwpKnD4ocaqgxOmDEqeKWCyWy+UEoQhKnCpoxemDEqcKSpw+KHGqoMTpgxKnCkqcPihxqqDE6YMSpwpGVOiDEqcKWnH6oMSpghKnD0qcKihx+qDEqYISpw9KnCoocfqgxKmCERX60Pv1ZCHTr1+/hIQEonolIjU11dzcXCqVKhSK69evE4RnDPjJbuR/ZuDAgenp6aDytLQ0hmFA6KDv0qVLE4R/UOI0aNmyZZUqVUDW6hRwV+rWrUsQ/kGJU2LQoEG2trbqj15eXr179yYI/6DEKdGwYcPq1atzIx/4W6tWrXLlyhGEf1Di9Bg2bJijoyNsuLm59e3blyBUQInTo0aNGrVr1wYvvGbNmpUqVSIIFTBoqIUTO+Jjn2WmJSsYEVGoJmoKtJGy1RgmXxIckT8B3BFS5DGqhIJfgLbDtOd9nyiSECsbsbuPeet+7gTJD0r8Ay8fp54MSchIUUDfZmIutrQ3h38mlhITsSSfvGBbwaj0lYdKafm0qlWlhGXeq5LNK4ctdCir+sAU/lK03AtyVtkLZ2fkZL7LykrJlWbJFHLW0kbcoINDlQB7gqhAieexeW5UWrLcwsaktH8pU/OSOukLM0rRt99mpeSYW4mHzPEmCEocuHs++dzeRDMbiW8D45mLeXY1Nutdjn9z20bfuBJhI3SJXzueeOVIcunaLnbO1sS4yM2WPT0XXaWuTWBvNyJgBC3x68eTroQl+bU05g79wYmoGo3tGndyIUJFuBI/vz/+7vl0v0Djd1gfnIoq52f+9UAvIkgEGhdPS8q5c0YQ+gb8WnhH3cmOuJtKBIlAJR68+JW9pxURDK4V7I9teUMEiRAlfnx7nIJlvPwEFGpw9XEQmYj2rXlFhIcQJR5xO8OxrA0RGB6VnF5FZBPhITiJXzr4FgbYbt6O5LMkPSN54vR6t++dIJ8aWzdrsZiEbY0lAkNw724+vpFuZm1KBImFg8WLh5lEYAjOimelyZ3KGNssj4G4VLCTCs9VEZYVj3uRAV6Kvbsd4YfUtMSD/6x4Hn03Nze7km/9lk0Hu7qUhfSL4buPn90wcvAfW0KmvH4T6e5WoUnD3nVqt+dy3bp7LOzkn1lZqVUrN276JY/PkVvZWBCG3LuUVL3hZ+qn8YGwrHjkHR67ablcvnbD98+e3+zaYfKE0cHWVo6/rxuckKgMYoglJllZafsOL+3R6Zclc8JrVGuxa9+85HfxsCvudUTwnhkBtdpNHhsa4P/1/sPLCJ8wDPPqaQ4REsKS+Ls3UpGIIfwQ9fL2m4TnvbvNrlyxga2NU4e2P1pZ2p+/HMLtlculrZoPLVu6OogMpAyTyjFxTyH90pVQe7tSrZoNsbS0reDzRb2AToRPRCZMRqqUCAlhOSq5OQqW8PXAwvMXd8RiE1+fAO4jSLm8d+3I57fUB5Tx9OM2LC2U7ylnZafB34Sk6FJuPupjSntWJXwiYkTSXL5u8s8TYUlcYiISicSEH7Ky08FUQ8hPM9HaykG9zTBatJWZmers9OEhXlNTC8In0HtIBBZFE9blWtuLWJav9dZsrJ1AoIP75nOm4ZbSnwv8E6lGmCMnJ4PwCUjcwlpY3qmwJO5ZweLhlXTCD57uFXNzs+zt3Zwd857pS0yK0bTiWnGwd3/4+LxCoeBuhodPLhA+YeWsa2kzIiSEdUNXrG0HrnhWKi8hBd/ydSr7Nti9bz6EStIz3l28sue3tQOv3jyoP1dNv5Ywo7nv8DKwrxGRNy5d2UP4RCFn/RvbEiEhuNlNUwvmbdS7MjV5eRFmcL/ll6/t3bZr2ovoey7OZWvXbNu4QU/9WSr51mvf5ofLV/dOmlEfQit9u89eHTSc8DMmjn38VmxCTC2FNbkruFcijmyMffkkq3LTckR4PDn30tlD0vUHYS0XKrgJ/HaDPOS5bFa6sKY/OKQ58raDBPcepxCX0HfyNIm+86bilzqN2bT5gVrTZbJciHxrjf2VcvEZ/d168un4a+v4qJd3tO6SSnNMTLQPGedNPUl0EBEeY+sosRLeI2gCfXdz9YSIsrXdrB0tte5NStb+xGl2drq5ufZHuEQiib3dp3zHIjU1QSbP1borIzPVylL7kNHRwYPo4P6xqNG/ViDCQ6A/hFK9kc39S6+rttD+7qYeoVDD1tZZ166PqN6jMy+8a1gSQSLQdzebdHazdZD8eymaCICoazEWVszXg/77+/Y/Qbgr0/b7pZxYonh4OooYNRBFkeXIBs4Q7uJvQl8Na8fS6NTk3EqNyhFj5OmllxIRGTxb0Isb4pqGoPIXyfHSUpWcHL2MZ9ov9W169N231raiATN8iLBBiSu5dizx2rFksUTk5uto71GyX85PTUiPe5QkzZZXb2DTtLugVzPkQIl/YO/qV3HPsglDzGxM7dwsXco5kJJDYvS7lNiMrPRcoiCuZUy7jy1DEBUo8YKcDX0dcSczK12ufk6EEb1f2Z68X+7+/S7l+vcaa9szjPKnIbiPGkvjs4yIYRXvczDcAerEvJS8ZDWFfzuCO4JhVUvxk7xt+L8ir2JmliLvqhYt++APReQDJa4TmO5+ejMlJUkOMzDsh1/MZFjlf3kfVHITqfXIav54hPqHUFjlyzYkr53f3yKMalvZ+vlKUP3eBJv/JlHmV21r/LYEo8qrYE2tGBt7U+9qlla2JgTRBkocMXIEOruJCAeUOGLkoMQRIwcljhg5KHHEyEGJI0bO/wMAAP//jCUOVAAAAAZJREFUAwCYaEgwlivNHAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Generate a visualization of the workflow graph\n",
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d213c884-fbdd-4bc1-a2c1-22ded7ccf73c"
      },
      "source": [
        "Now we are defining the input for the workflow by providing a job description, and then invoking the compiled app with this input to run the entire prompt chaining process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "9a57cad3-94d9-4705-9e6b-592a77d8600f"
      },
      "outputs": [],
      "source": [
        "input_state = {\n",
        "        \"job_description\": \"We are looking for a data scientist with experience in machine learning, NLP, and Python. Prior work with large datasets and experience deploying models into production is required.\"\n",
        "}\n",
        "\n",
        "result = app.invoke(input_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "224ac520-c465-4ee6-8746-3b22cbfb3824"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'**Resume Summary:**\\n\\nResults-driven Data Scientist with extensive experience in machine learning and natural language processing (NLP). Proficient in Python and adept at handling large datasets, I have a proven track record of deploying robust models into production environments. Demonstrated ability to leverage analytical skills to drive business insights and optimize performance through data-driven strategies. Passionate about translating complex data into actionable solutions that enhance decision-making and operational efficiency.'"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result['resume_summary']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6e062ce-2126-49f5-9ccd-03e004b62304"
      },
      "source": [
        "### Workflow Pattern: Routing\n",
        "\n",
        "Routing is a pattern where an LLM (or small router agent) **classifies or interprets incoming input** and then **routes it to the appropriate sub-process** or agent. This design is helpful when you're dealing with **multiple types of tasks or user intents**, and you want specialized logic or handling for each case.\n",
        "\n",
        "It works like a switchboard — one intelligent node (a classifier or router) analyzes the input and directs it to the correct branch.\n",
        "\n",
        "#### Use Cases:\n",
        "- AI customer service bots (route billing, tech support, or general inquiries)\n",
        "- Multi-skill agents (for example, summarization, translation, and data extraction)\n",
        "- Adaptive education bots (route to math, science, or grammar modules)\n",
        "\n",
        "---\n",
        "\n",
        "#### Routing Techniques:\n",
        "1. **Hard-coded keyword-based routing** (primitive)\n",
        "2. **LLM-based routing** using classification prompts\n",
        "3. **Embedding-based semantic matching** with a routing map\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58210f86-8542-4441-b42c-a8f9dc184387"
      },
      "source": [
        "### Use Case: Routing — Task Classifier for Summarization and Translation\n",
        "\n",
        "In this workflow, we are going to build a simple **task router** using the Routing design pattern. The goal is to create a system that can intelligently decide whether the user wants to **summarize** or **translate** a given input, and then send it to the appropriate processing path.\n",
        "\n",
        "This pattern is useful when the system needs to handle **multiple types of tasks** based on the user’s intent. Instead of creating one large model to handle everything, we let a **router node** classify the request and direct it to a **specialized sub-process**.\n",
        "\n",
        "For example:\n",
        "- If the input is “Summarize this article about AI,” the router sends it to the **summarizer**.\n",
        "- If the input is “Translate this to French,” it sends it to the **translator**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5beaaee-7df0-4c19-ae05-933b2f580158"
      },
      "source": [
        "Now we are defining the `RouterState` using `TypedDict` to represent the shared state in our routing workflow. This state includes:\n",
        "\n",
        "- `user_input`: the raw input provided by the user,\n",
        "- `task_type`: the type of task determined by the router (for example, \"summarize\" or \"translate\"),\n",
        "- `output`: the final result generated after routing to the appropriate task handler.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "048d8051-e135-4d48-8a1f-d847ec999e93"
      },
      "outputs": [],
      "source": [
        "class RouterState(TypedDict):\n",
        "    user_input: str\n",
        "    task_type: str\n",
        "    output: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "236e62f0-2c8e-4416-8322-b1ac5d2aa81b"
      },
      "source": [
        "Now we are defining the `router_node`, which acts as the decision-maker in the workflow. It sends a prompt to the LLM asking it to classify the user's intent as either `\"summarize\"` or `\"translate\"`. The result is stored in the `task_type` field of the state and will determine which processing node the workflow routes to next.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "e186190b-b272-414f-be56-0f915fffdbd6"
      },
      "outputs": [],
      "source": [
        "class Router(BaseModel):\n",
        "    role: str = Field(..., description=\"Decide whether the user wants to summarize a passage  ouput 'summarize'  or translate text into French oupput translate.\")\n",
        "llm_router=llm.bind_tools([Router])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "3bb6a9a8-0eb9-4eda-b06b-adcefdb392f7"
      },
      "outputs": [],
      "source": [
        "response=llm_router.invoke(\"summarize this I love the sun its so warm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "f36c4154-e2c7-4c17-965f-5db84313cec3"
      },
      "outputs": [],
      "source": [
        "def router_node(state: RouterState) -> RouterState:\n",
        "    routing_prompt = f\"\"\"\n",
        "    You are an AI task classifier.\n",
        "\n",
        "    Decide whether the user wants to:\n",
        "    - \"summarize\" a passage\n",
        "    - or \"translate\" text into French\n",
        "\n",
        "    Respond with just one word: 'summarize' or 'translate'.\n",
        "\n",
        "    User Input: \"{state['user_input']}\"\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm_router.invoke(routing_prompt)\n",
        "\n",
        "    return {**state, \"task_type\": response.tool_calls[0]['args']['role']} # This becomes the next node's name!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "758301eb-45e1-4077-852b-912a15b6a6a3"
      },
      "source": [
        "Now we are defining the `router` function, which simply returns the `task_type` from the state. This value will be used by LangGraph to decide which node to route to next based on the classification result.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "d095c645-bc32-45c9-bd9c-a3082b4d059e"
      },
      "outputs": [],
      "source": [
        "def router(state: RouterState) -> str:\n",
        "    return state['task_type']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc10b4ec-6704-4082-8116-54d33aac723e"
      },
      "source": [
        "Now we are defining the `summarize_node`, which is responsible for summarizing the user's input. It prompts the LLM to generate a concise summary and stores the result in the `output` field, while also confirming the `task_type` as `\"summarize\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "472b5752-a7d0-4482-a1d6-c707ef824f14"
      },
      "outputs": [],
      "source": [
        "def summarize_node(state: RouterState) -> RouterState:\n",
        "    prompt = f\"Please summarize the following passage:\\n\\n{state['user_input']}\"\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    return {**state, \"task_type\": \"summarize\", \"output\": response.content}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffc7e057-e957-4a2f-8c43-3ce4b84cb810"
      },
      "source": [
        "Now we are defining the `translate_node`, which handles translation tasks. It prompts the LLM to translate the user's input into French and saves the translated text in the `output` field, while also updating the `task_type` to `\"translate\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "2b9fe748-9ff9-4d5b-82c2-5f321e7365cd"
      },
      "outputs": [],
      "source": [
        "def translate_node(state: RouterState) -> RouterState:\n",
        "    prompt = f\"Translate the following text to French:\\n\\n{state['user_input']}\"\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    return {**state, \"task_type\": \"translate\", \"output\": response.content}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27354e76-f9cf-4084-b29d-e30fcd5dc15a"
      },
      "source": [
        "Now we are initializing a new `StateGraph` using the `RouterState` type. This sets up the structure of our routing workflow and defines the schema for the state that will be passed between nodes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "6bbe865c-8400-42d6-829e-449bc93edf26"
      },
      "outputs": [],
      "source": [
        "workflow = StateGraph(RouterState)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49765272-2ac5-49f4-81ff-2bc0ae7cfdca"
      },
      "source": [
        "Now we are adding three nodes to the workflow:\n",
        "\n",
        "- `\"router\"`: the node that classifies the user input,  \n",
        "- `\"summarize\"`: the node that handles summarization,  \n",
        "- `\"translate\"`: the node that handles translation.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "46718db8-5871-44eb-9363-772de93d5493"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab4c2410>"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_node(\"router\", router_node)\n",
        "workflow.add_node(\"summarize\", summarize_node)\n",
        "workflow.add_node(\"translate\", translate_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "709d3459-cd29-4aa0-9e5c-94665d805bf4"
      },
      "source": [
        "Now we are setting `\"router\"` as the entry point of the workflow, meaning the execution will start by classifying the user’s intent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "60e430c1-390a-40ce-a2cb-48ce552aa641"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab4c2410>"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.set_entry_point(\"router\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3e76374-7bd9-461a-bab6-ab4f8f2e7c42"
      },
      "source": [
        "Now we are adding conditional edges from the `\"router\"` node based on the value returned by the `router` function. If the task is `\"summarize\"`, the workflow routes to the `summarize` node; if it's `\"translate\"`, it routes to the `translate` node.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "dbff9eb0-d30c-4f4b-96c4-05eed923c1af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab4c2410>"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.add_conditional_edges(\"router\", router, {\n",
        "    \"summarize\": \"summarize\",\n",
        "    \"translate\": \"translate\"\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0580b5ab-4af6-413f-9f1e-1bac0be79fbe"
      },
      "source": [
        "Now we are marking both `\"summarize\"` and `\"translate\"` as valid finish points. This means the workflow can end after executing either node, depending on the task type selected by the router.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "2476340e-364e-4748-9f86-64092c508937"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab4c2410>"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow.set_finish_point(\"summarize\")\n",
        "workflow.set_finish_point(\"translate\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beba1edf-faa0-4bec-a2b1-47de5954b10f"
      },
      "source": [
        "We compile the workflow into an executable app using the `compile()` method. This step prepares the defined nodes and routing logic so the workflow can be run with actual input data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "2d616a55-273c-4357-a4cc-ef2c183e5f6a"
      },
      "outputs": [],
      "source": [
        "app = workflow.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7a4b0a7-44bf-4108-a5aa-5c7088740663"
      },
      "source": [
        "To better understand the structure of our workflow, we use `app.get_graph().draw_png()` to generate a visual representation of the graph. This diagram helps us verify how nodes are connected and where conditional routing decisions lead within the workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "5c9f004f-47fd-4e43-953e-fc26c8494c25"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Generate a visualization of the workflow graph\n",
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35dfbfe3-df5a-4251-b8b2-3d8eb2ffbb27"
      },
      "source": [
        "In this step, we provide a minimal input containing only the `user_input` field. Since the state is defined using `TypedDict`, missing fields such as `task_type` and `output` will be automatically handled during execution. We then invoke the app with this input, which starts the routing process and executes the appropriate task based on the user's intent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "aab6494a-c61e-447a-80b1-9c13b0b0ce54"
      },
      "outputs": [],
      "source": [
        "input_text = {\n",
        "        \"user_input\": \"Can you translate this sentence: I love programming?\"\n",
        "    }\n",
        "\n",
        "result = app.invoke(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "a8b30928-5e9d-47c5-a844-f72885dd8cc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure! The translation of \"I love programming\" in French is \"J'aime la programmation.\"\n",
            "translate\n"
          ]
        }
      ],
      "source": [
        "print(result[ 'output'])\n",
        "print(result['task_type'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ae9c8b6-1330-44a1-b0f1-5e7b5b5ee072"
      },
      "source": [
        "Let's try the second task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "e868d2d0-075a-4ff7-8b39-e709d21c8064"
      },
      "outputs": [],
      "source": [
        "input_text = {\n",
        "        \"user_input\": \"Can you summarize this sentence: I love programming so much it is the best thing ever. All I want to do is programming?\"\n",
        "    }\n",
        "\n",
        "result = app.invoke(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "8faf5405-5d51-4d8d-853d-d7c38abe0e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The author expresses a deep passion for programming, considering it the best activity and their primary interest.\n",
            "summarize\n"
          ]
        }
      ],
      "source": [
        "print(result[ 'output'])\n",
        "print(result['task_type'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e0d7139-6f0d-4577-8d3c-b53531508f7b"
      },
      "source": [
        "### Workflow Pattern: Parallelization\n",
        "\n",
        "Parallelization is a pattern where **multiple LLM tasks are executed at the same time** instead of one after another. This is useful when different parts of the task can be done **independently**, allowing for faster processing and better system throughput.\n",
        "\n",
        "Think of it like a kitchen where one chef is chopping vegetables, another is boiling pasta, and another is baking — all at once. None of them need to wait for the other to finish.\n",
        "\n",
        "In AI workflows, this means breaking a problem into parts and running them **in parallel**, then collecting and combining the outputs.\n",
        "\n",
        "#### Use Cases:\n",
        "- Summarizing different sections of a large document simultaneously\n",
        "- Translating a batch of user messages at once\n",
        "- Generating multiple variations of an ad copy or product description\n",
        "- Running safety checks using different prompts and comparing outputs\n",
        "- Ensembling results from different models or prompts for consensus\n",
        "\n",
        "---\n",
        "\n",
        "#### Parallelization Techniques:\n",
        "1. **Format Diversity (Multi-Output Tasks)**  \n",
        "   - Run the **same input** through **different prompt styles, languages, or output formats**  \n",
        "   - Each LLM call produces a distinct kind of result in parallel  \n",
        "   - Combine all outputs into a unified response  \n",
        "   - *Example:* Translate a sentence into French, Spanish, and Japanese at the same time\n",
        "\n",
        "2. **Task Splitting (Sectioning)**  \n",
        "   - Divide a large input into smaller parts  \n",
        "   - Run each part through the same task (for example, summarization) in parallel  \n",
        "   - Merge the partial results for a final outcome  \n",
        "   - *Example:* Summarize each paragraph of an article simultaneously\n",
        "\n",
        "3. **Consensus Voting (Multi-Agent Evaluation)**  \n",
        "   - Run the **same task** multiple times with different agents or prompt styles  \n",
        "   - Compare the responses and choose the best one via ranking or majority vote  \n",
        "   - *Example:* Ask 3 variations of a model to write a safe response and pick the most appropriate one\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95effb21-14ca-4300-a6f3-d4888ff2d3c7"
      },
      "source": [
        "### ⚡ Use Case: Parallelization — Multilingual Translation Assistant\n",
        "\n",
        "In this workflow, we are building a **multilingual translation assistant** using the Parallelization design pattern. The goal is to take a single English sentence and generate its translations into **French**, **Spanish**, and **Japanese** — all at the same time.\n",
        "\n",
        "Parallelization is ideal for this task because the translations are **independent of one another**. Since each language-specific translation can be processed separately, we can run them in **parallel** to save time and improve efficiency.\n",
        "\n",
        "Once all translations are completed, we aggregate the outputs into a **single multilingual result**, making it easy to present or store all versions together.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "722ac125-ef45-4eff-adae-a09a7bbdc554"
      },
      "source": [
        "To manage the data flowing through our parallel translation workflow, we define a `State` using `TypedDict`. This structure allows us to keep track of both the input and the individual outputs from each parallel task.\n",
        "\n",
        "- `text`: stores the original English sentence to be translated\n",
        "- `french`: will hold the French translation\n",
        "- `spanish`: will hold the Spanish translation\n",
        "- `japanese`: will hold the Japanese translation\n",
        "- `combined_output`: will store the final combined result of all translations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "62c2f441-15a9-415f-addb-5d07704dc109"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    text: str\n",
        "    french: str\n",
        "    spanish: str\n",
        "    japanese: str\n",
        "    combined_output: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "890ff1ab-4fa8-42b1-8f4d-2f6fef30cd20"
      },
      "source": [
        "Here, we define the `translate_french` node, which is responsible for translating the input text into French. It sends a prompt to the LLM asking for the French version of the input, and then stores the result in the `french` field of the state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "f90535c4-366f-4d56-a530-de8a7cb5f120"
      },
      "outputs": [],
      "source": [
        "def translate_french(state: State) -> dict:\n",
        "    response = llm.invoke(f\"Translate the following text to French:\\n\\n{state['text']}\")\n",
        "    return {\"french\": response.content.strip()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8f597c5-163d-43b0-84d5-1a1463db3b57"
      },
      "source": [
        "In the same way, we define the `translate_spanish` node to handle translation into Spanish. It prompts the LLM with the input text and stores the translated result in the `spanish` field of the state.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "3dfb374c-500f-402c-bea4-14673d71989f"
      },
      "outputs": [],
      "source": [
        "def translate_spanish(state: State) -> dict:\n",
        "    response = llm.invoke(f\"Translate the following text to Spanish:\\n\\n{state['text']}\")\n",
        "    return {\"spanish\": response.content.strip()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "421803b5-63d9-4eb9-a752-5661288ac68e"
      },
      "source": [
        "Similarly, we’ll create a `translate_japanese` node to translate the input text into Japanese and store the result in the `japanese` field.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "824bfa45-54fc-4e9a-852d-34be12561178"
      },
      "outputs": [],
      "source": [
        "def translate_japanese(state: State) -> dict:\n",
        "    response = llm.invoke(f\"Translate the following text to Japanese:\\n\\n{state['text']}\")\n",
        "    return {\"japanese\": response.content.strip()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3a6d74f-117a-4d27-8466-4d3c9156a92b"
      },
      "source": [
        "The `aggregator` node is responsible for combining the outputs from all three translation nodes into a single, readable format. It constructs a formatted string that includes the original text along with its French, Spanish, and Japanese translations, and stores the final result in the `combined_output` field.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "5ccd17ec-45d3-4060-b8cc-ee9b7cd209a3"
      },
      "outputs": [],
      "source": [
        "def aggregator(state: State) -> dict:\n",
        "    combined = f\"Original Text: {state['text']}\\n\\n\"\n",
        "    combined += f\"French: {state['french']}\\n\\n\"\n",
        "    combined += f\"Spanish: {state['spanish']}\\n\\n\"\n",
        "    combined += f\"Japanese: {state['japanese']}\\n\"\n",
        "    return {\"combined_output\": combined}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dad679fc-acfe-4c2d-8481-60fa54aa69ba"
      },
      "source": [
        "We initialize a new `StateGraph` using the `State` type. This sets up the foundation for our parallel workflow and defines the structure of the data that will flow between nodes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "aa2ae597-a5c3-4edc-a37e-da89e1f4e8ac"
      },
      "outputs": [],
      "source": [
        "graph = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9110e7c7-05e5-4856-96ed-0e2332c5123d"
      },
      "source": [
        "We add four nodes to the graph:\n",
        "\n",
        "- `\"translate_french\"`: handles translation to French,  \n",
        "- `\"translate_spanish\"`: handles translation to Spanish,  \n",
        "- `\"translate_japanese\"`: handles translation to Japanese,  \n",
        "- `\"aggregator\"`: collects and combines all translations into one output.\n",
        "\n",
        "Each of these nodes will operate independently before merging at the aggregator.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "6aa4be55-3a88-434e-b288-d6b5bc20058d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab500d90>"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph.add_node(\"translate_french\", translate_french)\n",
        "graph.add_node(\"translate_spanish\", translate_spanish)\n",
        "graph.add_node(\"translate_japanese\", translate_japanese)\n",
        "graph.add_node(\"aggregator\", aggregator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "405396ad-283b-435b-8d36-cc74f7112917"
      },
      "source": [
        "We connect the three translation nodes to the `START` of the workflow. This means all translation tasks will begin simultaneously in parallel as soon as the workflow is triggered.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "cdf6d5c4-f4af-40c0-86ba-2755671aa3b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab500d90>"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Connect parallel nodes from START\n",
        "graph.add_edge(START, \"translate_french\")\n",
        "graph.add_edge(START, \"translate_spanish\")\n",
        "graph.add_edge(START, \"translate_japanese\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e5ab3b5-0aca-451f-83fe-e066f78a3d03"
      },
      "source": [
        "Here, we connect each of the translation nodes to the `aggregator` node. Once all translations are complete, their outputs will be passed to the aggregator to be combined into the final result.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "337bca40-d317-40bf-88ee-54ca0c5dea15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab500d90>"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Connect all translation nodes to the aggregator\n",
        "graph.add_edge(\"translate_french\", \"aggregator\")\n",
        "graph.add_edge(\"translate_spanish\", \"aggregator\")\n",
        "graph.add_edge(\"translate_japanese\", \"aggregator\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a7756c4-1a60-4afc-9d99-45d86144b3cc"
      },
      "source": [
        "We connect the `aggregator` node to the `END` of the workflow, marking it as the final step where the combined output is returned.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "7ac6d901-b83f-41f0-bf70-fde39f6317d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x19cab500d90>"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Final node\n",
        "graph.add_edge(\"aggregator\", END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "ad3e3449-51a0-4edb-ace0-0809ea449a6f"
      },
      "outputs": [],
      "source": [
        "# Compile the graph\n",
        "app = graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b637ebd8-d215-4434-93c3-b415d0b166ba"
      },
      "source": [
        "We provide an English sentence as input under the `text` field and invoke the workflow. This triggers all translation tasks in parallel, and once completed, the translations are combined and returned as the final result.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "12222781-9ce8-4434-86b1-d20e62e5e8dd"
      },
      "outputs": [],
      "source": [
        "input_text = {\n",
        "        \"text\": \"Good morning! I hope you have a wonderful day.\"\n",
        "}\n",
        "\n",
        "result = app.invoke(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "8a0e2be4-4a64-4ce8-bf39-7c77cc239f76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'Good morning! I hope you have a wonderful day.',\n",
              " 'french': \"Bonjour ! J'espère que vous passerez une journée merveilleuse.\",\n",
              " 'spanish': '¡Buenos días! Espero que tengas un día maravilloso.',\n",
              " 'japanese': 'おはようございます！素晴らしい一日をお過ごしください。',\n",
              " 'combined_output': \"Original Text: Good morning! I hope you have a wonderful day.\\n\\nFrench: Bonjour ! J'espère que vous passerez une journée merveilleuse.\\n\\nSpanish: ¡Buenos días! Espero que tengas un día maravilloso.\\n\\nJapanese: おはようございます！素晴らしい一日をお過ごしください。\\n\"}"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4defbfcc-5e24-4a5c-a756-3ded488f56bf"
      },
      "source": [
        "### Exercises: Building a Multi-Agent Routing System\n",
        "\n",
        "\n",
        "#### Exercise 1 - Create State Management and Router Tool\n",
        "Define the state structure and classification tool for your multi-agent routing system. You need to create a TypedDict for state management and a Pydantic model for LLM tool binding.\n",
        "\n",
        "Your task: Create the foundational components for routing between ride hailing, restaurant orders, groceries, and default handling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c82c1e66-b949-4bd6-8a40-9beba5dcbf09"
      },
      "source": [
        "<details>\n",
        "    <summary>Click here for the solution</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "class RouterState(TypedDict):\n",
        "    user_input: str\n",
        "    task_type: str\n",
        "    output: str\n",
        "\n",
        "class Router(BaseModel):\n",
        "    role: str = Field(\n",
        "        ...,\n",
        "        description=\"Classify the user request. Return exactly one of: 'ride_hailing_call', 'restaurant_order', 'groceries' and if you do not know output 'default_handler'\"\n",
        "    )\n",
        "\n",
        "llm_router = llm.bind_tools([Router])\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "731e3b4f-110d-4924-b4b6-acfd1d65db4d"
      },
      "outputs": [],
      "source": [
        "# TODO: Define your RouterState TypedDict with three fields\n",
        "# TODO: Create a Router BaseModel with proper field description\n",
        "# TODO: Bind the router tool to your LLM\n",
        "class RouterState(TypedDict):\n",
        "    user_input: str\n",
        "    task_type: str\n",
        "    output: str\n",
        "\n",
        "class Router(BaseModel):\n",
        "    role: str = Field(\n",
        "        ...,\n",
        "        description=\"Classify the user request. Return exactly one of: 'ride_hailing_call', 'restaurant_order', 'groceries' and if you do not know output 'default_handler'\"\n",
        "    )\n",
        "\n",
        "llm_router = llm.bind_tools([Router])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3623ef2-91b7-47bd-bce7-c71c39e0176d"
      },
      "source": [
        "\n",
        "#### Exercise 2 - Implement Router Logic\n",
        "\n",
        "Create the router node function that classifies user input and handles cases where the LLM doesn't return a tool call. Also implement the router decision function.\n",
        "\n",
        "Your task: Build the classification logic with proper error handling for unclassified requests.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cc99597-27ed-4a90-9e7f-e594f5d700ab"
      },
      "source": [
        "<details>\n",
        "    <summary>Click here for the solution</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "def router_node(state: RouterState) -> RouterState:\n",
        "    response = llm_router.invoke(state['user_input'])\n",
        "    \n",
        "    if response.tool_calls:\n",
        "        tool_call = response.tool_calls[0]['args']['role']\n",
        "        return {**state, \"task_type\": tool_call}\n",
        "    else:\n",
        "        return {**state, \"task_type\": \"default_handler\"}\n",
        "\n",
        "def router(state: RouterState) -> str:\n",
        "    return state['task_type']\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "08ce036f-3625-4f20-9425-de216a8f820e"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement router_node function with tool call handling\n",
        "# TODO: Add fallback to \"default_handler\" when no tool calls\n",
        "# TODO: Create router function that returns task_type from state\n",
        "def router_node(state: RouterState) -> RouterState:\n",
        "    response = llm_router.invoke(state['user_input'])\n",
        "\n",
        "    if response.tool_calls:\n",
        "        tool_call = response.tool_calls[0]['args']['role']\n",
        "        return {**state, \"task_type\": tool_call}\n",
        "    else:\n",
        "        return {**state, \"task_type\": \"default_handler\"}\n",
        "\n",
        "def router(state: RouterState) -> str:\n",
        "    return state['task_type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "6b983d1b-5b78-4e7d-a112-4b6c79681192"
      },
      "outputs": [],
      "source": [
        "def ride_hailing_node(state: RouterState) -> RouterState:\n",
        "    \"\"\"\n",
        "    Processes ride hailing requests by extracting pickup/dropoff locations and preferences\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a ride hailing assistant. Based on the user's request, extract and organize the following information:\n",
        "\n",
        "    - Pickup location\n",
        "    - Destination/dropoff location\n",
        "    - Preferred ride type (if mentioned)\n",
        "    - Any special requirements\n",
        "    - Estimated timing preferences\n",
        "\n",
        "    User Request: \"{state['user_input']}\"\n",
        "\n",
        "    Provide a clear summary of the ride request with all available details.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"task_type\": \"ride_hailing_call\",\n",
        "        \"output\": response.content.strip()\n",
        "    }\n",
        "\n",
        "def restaurant_order_node(state: RouterState) -> RouterState:\n",
        "    \"\"\"\n",
        "    Processes restaurant orders by organizing menu items, quantities, and preferences\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a restaurant ordering assistant. Based on the user's request, organize the following information:\n",
        "\n",
        "    - Menu items requested\n",
        "    - Quantities for each item\n",
        "    - Special modifications or dietary restrictions\n",
        "    - Delivery or pickup preference\n",
        "    - Any timing requirements\n",
        "\n",
        "    User Request: \"{state['user_input']}\"\n",
        "\n",
        "    Provide a clear, organized summary of the restaurant order with all details.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"task_type\": \"restaurant_order\",\n",
        "        \"output\": response.content.strip()\n",
        "    }\n",
        "\n",
        "def groceries_node(state: RouterState) -> RouterState:\n",
        "    \"\"\"\n",
        "    Processes grocery delivery requests with driver pickup service\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a grocery delivery assistant for a service where our drivers pick up groceries for customers.\n",
        "\n",
        "    Based on the user's request, organize the following information:\n",
        "\n",
        "    Shopping List:\n",
        "    - List of grocery items needed\n",
        "    - Quantities or amounts for each item\n",
        "    - Brand preferences (if mentioned)\n",
        "    - Any dietary restrictions or organic preferences\n",
        "\n",
        "    Store Information:\n",
        "    - Preferred store or location\n",
        "    - Budget considerations\n",
        "    - Special instructions for finding items\n",
        "\n",
        "    Delivery Details:\n",
        "    - Delivery address (if provided)\n",
        "    - Preferred delivery time window\n",
        "    - Any special delivery instructions\n",
        "    - Contact information for driver coordination\n",
        "\n",
        "    Driver Instructions:\n",
        "    - Substitution preferences (if item unavailable)\n",
        "    - How to handle out-of-stock items\n",
        "    - Any items requiring special handling (fragile, cold items)\n",
        "    - Payment method (if mentioned)\n",
        "\n",
        "    User Request: \"{state['user_input']}\"\n",
        "\n",
        "    Provide a comprehensive delivery order summary that our driver can use to efficiently shop and deliver groceries.\n",
        "    Include estimated pickup time and any special notes for the shopping trip.\n",
        "\n",
        "    Format the response as a clear, organized delivery order that includes all necessary details for our driver service.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"task_type\": \"groceries\",\n",
        "        \"output\": response.content.strip()\n",
        "    }\n",
        "def default_handler_node(state: RouterState) -> RouterState:\n",
        "    prompt = f\"\"\"\n",
        "    I couldn't classify your request into a specific category.\n",
        "    Let me provide general assistance for: \"{state['user_input']}\"\n",
        "\n",
        "    I can help you with:\n",
        "    - Ride hailing services\n",
        "    -  Restaurant orders\n",
        "    -  Grocery shopping\n",
        "\n",
        "    Please rephrase your request to match one of these services, or if you need assistance with something else, I will connect you with our customer support team who can provide personalized help.\n",
        "\n",
        "    Would you like me to:\n",
        "    1. Help you rephrase your request for one of our services\n",
        "    2. Connect you with customer support for additional assistance\n",
        "    \"\"\"\n",
        "    response = llm.invoke(prompt)\n",
        "    return {**state, \"task_type\": \"default_handler\", \"output\": response.content.strip()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea7cf96a-70ba-42c9-8ca8-01e3666393cd"
      },
      "source": [
        "#### Exercise 3 - Assemble the Complete Workflow\n",
        "\n",
        "Put all the pieces together by building the StateGraph, adding nodes, setting up routing logic, and compiling the application.\n",
        "\n",
        "Your task: Create the complete workflow graph with proper routing and finish points, and call it ```app```.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c12d2954-b966-4f2a-bcc1-10ffa391dc6c"
      },
      "source": [
        "<details>\n",
        "    <summary>Click here for the solution</summary>\n",
        "\n",
        "```python\n",
        "workflow = StateGraph(RouterState)\n",
        "\n",
        "# Add all nodes\n",
        "workflow.add_node(\"router\", router_node)\n",
        "workflow.add_node(\"ride_hailing_call\", ride_hailing_node)\n",
        "workflow.add_node(\"restaurant_order\", restaurant_order_node)\n",
        "workflow.add_node(\"groceries\", groceries_node)\n",
        "workflow.add_node(\"default_handler\", default_handler_node)\n",
        "\n",
        "# Set entry point\n",
        "workflow.set_entry_point(\"router\")\n",
        "\n",
        "# Add conditional routing\n",
        "workflow.add_conditional_edges(\"router\", router, {\n",
        "    \"groceries\": \"groceries\",\n",
        "    \"restaurant_order\": \"restaurant_order\",\n",
        "    \"ride_hailing_call\": \"ride_hailing_call\",\n",
        "    \"default_handler\": \"default_handler\"\n",
        "})\n",
        "\n",
        "# Set finish points\n",
        "workflow.set_finish_point(\"ride_hailing_call\")\n",
        "workflow.set_finish_point(\"restaurant_order\")\n",
        "workflow.set_finish_point(\"groceries\")\n",
        "workflow.set_finish_point(\"default_handler\")\n",
        "\n",
        "# Compile the application\n",
        "app = workflow.compile()\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "38ef7a0c-38df-4901-9958-6bfc7448471c"
      },
      "outputs": [],
      "source": [
        "# TODO: Create StateGraph with RouterState\n",
        "# TODO: Add all five nodes (router + 4 processing nodes)\n",
        "# TODO: Set router as entry point\n",
        "# TODO: Add conditional edges with all four routing options\n",
        "# TODO: Set finish points for all processing nodes\n",
        "# TODO: Compile the application\n",
        "workflow = StateGraph(RouterState)\n",
        "# Add all nodes\n",
        "workflow.add_node(\"router\", router_node)\n",
        "workflow.add_node(\"ride_hailing_call\", ride_hailing_node)\n",
        "workflow.add_node(\"restaurant_order\", restaurant_order_node)\n",
        "workflow.add_node(\"groceries\", groceries_node)\n",
        "workflow.add_node(\"default_handler\", default_handler_node)\n",
        "\n",
        "# Set entry point\n",
        "workflow.set_entry_point(\"router\")\n",
        "\n",
        "# Add conditional routing\n",
        "workflow.add_conditional_edges(\"router\", router, {\n",
        "    \"groceries\": \"groceries\",\n",
        "    \"restaurant_order\": \"restaurant_order\",\n",
        "    \"ride_hailing_call\": \"ride_hailing_call\",\n",
        "    \"default_handler\": \"default_handler\"\n",
        "})\n",
        "\n",
        "# Set finish points\n",
        "workflow.set_finish_point(\"ride_hailing_call\")\n",
        "workflow.set_finish_point(\"restaurant_order\")\n",
        "workflow.set_finish_point(\"groceries\")\n",
        "workflow.set_finish_point(\"default_handler\")\n",
        "\n",
        "# Compile the application\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28d2c19b-6cfc-49e6-8053-9127dfd9e288"
      },
      "source": [
        "Test your implementation here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "aae419b8-f833-418f-84e1-f401ac66343c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "question I need a ride from downtown to the airport at 3pm\n",
            "\n",
            "task_type ride_hailing_call\n",
            "\n",
            "output: **Ride Request Summary:**\n",
            "\n",
            "- **Pickup Location:** Downtown\n",
            "- **Destination/Dropoff Location:** Airport\n",
            "- **Preferred Ride Type:** Not mentioned\n",
            "- **Special Requirements:** None specified\n",
            "- **Estimated Timing Preferences:** 3 PM\n",
            "\n",
            "-----------------------------------\n",
            "question I want to order 2 large pepperoni pizzas for delivery\n",
            "\n",
            "task_type restaurant_order\n",
            "\n",
            "output: ### Order Summary\n",
            "\n",
            "- **Menu Items Requested:**\n",
            "  - 2 Large Pepperoni Pizzas\n",
            "\n",
            "- **Quantities:**\n",
            "  - Large Pepperoni Pizzas: 2\n",
            "\n",
            "- **Special Modifications or Dietary Restrictions:**\n",
            "  - None specified\n",
            "\n",
            "- **Delivery or Pickup Preference:**\n",
            "  - Delivery\n",
            "\n",
            "- **Timing Requirements:**\n",
            "  - None specified\n",
            "\n",
            "This order includes two large pepperoni pizzas for delivery, with no special modifications or dietary restrictions noted.\n",
            "\n",
            "-----------------------------------\n",
            "question I need milk, bread, eggs, and vegetables for the week\n",
            "\n",
            "task_type groceries\n",
            "\n",
            "output: ### Grocery Delivery Order Summary\n",
            "\n",
            "#### Shopping List:\n",
            "- **Items Needed:**\n",
            "  - Milk\n",
            "  - Bread\n",
            "  - Eggs\n",
            "  - Vegetables\n",
            "\n",
            "- **Quantities/Amounts:**\n",
            "  - Milk: 1 gallon\n",
            "  - Bread: 1 loaf\n",
            "  - Eggs: 1 dozen\n",
            "  - Vegetables: 1 pound (specific types can be requested if needed; otherwise, a mix of common vegetables is preferred)\n",
            "\n",
            "- **Brand Preferences:**\n",
            "  - (No specific brands mentioned)\n",
            "\n",
            "- **Dietary Restrictions/Organic Preferences:**\n",
            "  - (No dietary restrictions or organic preferences mentioned)\n",
            "\n",
            "#### Store Information:\n",
            "- **Preferred Store:**\n",
            "  - Local supermarket (please select the closest one available)\n",
            "\n",
            "- **Budget Considerations:**\n",
            "  - (No specific budget mentioned)\n",
            "\n",
            "- **Special Instructions for Finding Items:**\n",
            "  - Look for fresh produce for vegetables; prioritize organic options if available.\n",
            "\n",
            "#### Delivery Details:\n",
            "- **Delivery Address:**\n",
            "  - (Address not provided; please add delivery address here)\n",
            "\n",
            "- **Preferred Delivery Time Window:**\n",
            "  - (Specific time not provided; please specify any available time slots)\n",
            "\n",
            "- **Special Delivery Instructions:**\n",
            "  - (No special instructions mentioned)\n",
            "\n",
            "- **Contact Information for Driver Coordination:**\n",
            "  - (Contact number not provided; please add contact info here)\n",
            "\n",
            "#### Driver Instructions:\n",
            "- **Substitution Preferences:**\n",
            "  - If any item is unavailable, please choose the closest alternative (e.g., whole milk for 2% milk).\n",
            "\n",
            "- **Handling Out-of-Stock Items:**\n",
            "  - If an item is out of stock, check for substitutes or leave it out upon agreement.\n",
            "\n",
            "- **Special Handling Items:**\n",
            "  - Milk and eggs should be handled carefully (fragile).\n",
            "\n",
            "- **Payment Method:**\n",
            "  - (Payment method not mentioned; please specify if applicable)\n",
            "\n",
            "### Estimated Pickup Time:\n",
            "- **Pickup Time:** Approximately 30 minutes after order confirmation, allowing for travel and shopping time.\n",
            "\n",
            "### Special Notes:\n",
            "- Ensure to check for the best quality vegetables and check expiration dates on dairy products (milk and eggs). \n",
            "\n",
            "Please confirm any missing details to finalize the order. Thank you!\n",
            "\n",
            "-----------------------------------\n",
            "question What's the weather like today?\n",
            "\n",
            "task_type default_handler\n",
            "\n",
            "output: It seems like your request might fall outside of the specific services I can assist with. However, if you want to know about the weather, you could ask for directions to a restaurant or inquire about ride hailing options for your activities today. \n",
            "\n",
            "Would you like me to:\n",
            "1. Help you find a nearby restaurant or activity based on the weather?\n",
            "2. Connect you with customer support for further assistance?\n",
            "\n",
            "-----------------------------------\n"
          ]
        }
      ],
      "source": [
        "test_cases = [\n",
        "    {\"user_input\": \"I need a ride from downtown to the airport at 3pm\"},\n",
        "    {\"user_input\": \"I want to order 2 large pepperoni pizzas for delivery\"},\n",
        "    {\"user_input\": \"I need milk, bread, eggs, and vegetables for the week\"},\n",
        "    {\"user_input\": \"What's the weather like today?\"},  # Default/unclassified example\n",
        "]\n",
        "\n",
        "for i, test_input in enumerate(test_cases, 1):\n",
        "    result=app.invoke(test_input)\n",
        "\n",
        "\n",
        "    print(f\"question {test_input['user_input']}\\n\")\n",
        "    print(f\"task_type {result['task_type']}\\n\")\n",
        "    print(f\"output: {result['output']}\\n\")\n",
        "    print('-----------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02872fc6-abf8-485a-9301-e8d9465f6887"
      },
      "source": [
        "Here is the complete code:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "5b76aead-e3de-496d-b558-c1cbc585ceaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "question I need a ride from downtown to the airport at 3pm\n",
            "\n",
            "task_type ride_hailing_call\n",
            "\n",
            "output: **Ride Request Summary:**\n",
            "\n",
            "- **Pickup Location:** Downtown\n",
            "- **Destination/Dropoff Location:** Airport\n",
            "- **Preferred Ride Type:** Not mentioned\n",
            "- **Special Requirements:** None mentioned\n",
            "- **Estimated Timing Preferences:** 3 PM\n",
            "\n",
            "-----------------------------------\n",
            "question I want to order 2 large pepperoni pizzas for delivery\n",
            "\n",
            "task_type restaurant_order\n",
            "\n",
            "output: ### Restaurant Order Summary\n",
            "\n",
            "- **Menu Items Requested:**\n",
            "  - Large Pepperoni Pizzas\n",
            "\n",
            "- **Quantities:**\n",
            "  - 2\n",
            "\n",
            "- **Special Modifications or Dietary Restrictions:**\n",
            "  - None specified\n",
            "\n",
            "- **Delivery or Pickup Preference:**\n",
            "  - Delivery\n",
            "\n",
            "- **Timing Requirements:**\n",
            "  - None specified\n",
            "\n",
            "Please confirm if you would like to add any additional details!\n",
            "\n",
            "-----------------------------------\n",
            "question I need milk, bread, eggs, and vegetables for the week\n",
            "\n",
            "task_type groceries\n",
            "\n",
            "output: ### Delivery Order Summary\n",
            "\n",
            "---\n",
            "\n",
            "**Shopping List:**\n",
            "- **Items Needed:**\n",
            "  - Milk: 1 gallon\n",
            "  - Bread: 1 loaf\n",
            "  - Eggs: 1 dozen\n",
            "  - Vegetables: Assorted (e.g., carrots, broccoli, spinach)\n",
            "  \n",
            "- **Quantities:**\n",
            "  - Milk: 1 gallon\n",
            "  - Bread: 1 loaf\n",
            "  - Eggs: 1 dozen\n",
            "  - Vegetables: 1 lb each of carrots, broccoli, and spinach (total 3 lbs)\n",
            "\n",
            "- **Brand Preferences:** No specific brands mentioned.\n",
            "\n",
            "- **Dietary Restrictions/Preferences:** No dietary restrictions or organic preferences indicated.\n",
            "\n",
            "---\n",
            "\n",
            "**Store Information:**\n",
            "- **Preferred Store/Location:** Local grocery store (please select the nearest option).\n",
            "- **Budget Considerations:** Keep all items within a reasonable budget (approx. $30).\n",
            "- **Special Instructions for Finding Items:** Ensure fresh vegetables; if necessary, choose organic options if they fit within the budget.\n",
            "\n",
            "---\n",
            "\n",
            "**Delivery Details:**\n",
            "- **Delivery Address:** [Please insert delivery address here]\n",
            "- **Preferred Delivery Time Window:** Between 2:00 PM and 4:00 PM.\n",
            "- **Special Delivery Instructions:** Knock on the door; leave items on the porch if no one answers.\n",
            "- **Contact Information for Driver Coordination:** [Please provide any necessary contact number or email]\n",
            "\n",
            "---\n",
            "\n",
            "**Driver Instructions:**\n",
            "- **Substitution Preferences:** If any item is unavailable, check for a similar item or the next best alternative (e.g., low-fat milk instead of whole).\n",
            "- **How to Handle Out-of-Stock Items:** Report back before completing the purchase to confirm item substitutions.\n",
            "- **Special Handling Items:** \n",
            "  - Milk and eggs should be handled carefully (fragile).\n",
            "  - Ensure vegetables remain cool during transport, especially in warm weather.\n",
            "- **Payment Method:** Payment will be processed through the grocery delivery service app.\n",
            "\n",
            "---\n",
            "\n",
            "### Estimated Pickup Time:\n",
            "- Expected pickup time is approximately **1:30 PM** if the order is confirmed promptly.\n",
            "\n",
            "---\n",
            "\n",
            "### Special Notes:\n",
            "- Please ensure to check the freshness of all perishable items.\n",
            "- Follow up with the customer if there are any significant issues regarding item availability or budget constraints.\n",
            "\n",
            "Thank you for your assistance in delivering this order!\n",
            "\n",
            "-----------------------------------\n",
            "question What's the weather like today?\n",
            "\n",
            "task_type default_handler\n",
            "\n",
            "output: It seems like there was a misunderstanding. If you'd like to know about the weather today, please let me know your location, and I can provide you with that information. If you need assistance with ride hailing, restaurant orders, or grocery shopping, just specify what you need help with!\n",
            "\n",
            "-----------------------------------\n"
          ]
        }
      ],
      "source": [
        "class RouterState(TypedDict):\n",
        "    user_input: str\n",
        "    task_type: str\n",
        "    output: str\n",
        "\n",
        "\n",
        "class Router(BaseModel):\n",
        "    role: str = Field(\n",
        "        ...,\n",
        "        description=\"Classify the user request. Return exactly one of: 'ride_hailing_call', 'restaurant_order',  'groceries' and if you do not know output  'default_handler'\"\n",
        "    )\n",
        "\n",
        "llm_router = llm.bind_tools([Router])\n",
        "\n",
        "def router_node(state: RouterState) -> RouterState:\n",
        "    response = llm_router.invoke(state['user_input'])\n",
        "\n",
        "    if response.tool_calls:\n",
        "        tool_call = response.tool_calls[0]['args']['role']\n",
        "        return {**state, \"task_type\": tool_call}\n",
        "    else:\n",
        "        return {**state, \"task_type\": \"default_handler\"}\n",
        "\n",
        "\n",
        "def router(state: RouterState) -> str:\n",
        "    return state['task_type']\n",
        "\n",
        "def ride_hailing_node(state: RouterState) -> RouterState:\n",
        "    \"\"\"\n",
        "    Processes ride hailing requests by extracting pickup/dropoff locations and preferences\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a ride hailing assistant. Based on the user's request, extract and organize the following information:\n",
        "\n",
        "    - Pickup location\n",
        "    - Destination/dropoff location\n",
        "    - Preferred ride type (if mentioned)\n",
        "    - Any special requirements\n",
        "    - Estimated timing preferences\n",
        "\n",
        "    User Request: \"{state['user_input']}\"\n",
        "\n",
        "    Provide a clear summary of the ride request with all available details.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"task_type\": \"ride_hailing_call\",\n",
        "        \"output\": response.content.strip()\n",
        "    }\n",
        "\n",
        "def restaurant_order_node(state: RouterState) -> RouterState:\n",
        "    \"\"\"\n",
        "    Processes restaurant orders by organizing menu items, quantities, and preferences\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a restaurant ordering assistant. Based on the user's request, organize the following information:\n",
        "\n",
        "    - Menu items requested\n",
        "    - Quantities for each item\n",
        "    - Special modifications or dietary restrictions\n",
        "    - Delivery or pickup preference\n",
        "    - Any timing requirements\n",
        "\n",
        "    User Request: \"{state['user_input']}\"\n",
        "\n",
        "    Provide a clear, organized summary of the restaurant order with all details.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"task_type\": \"restaurant_order\",\n",
        "        \"output\": response.content.strip()\n",
        "    }\n",
        "\n",
        "def groceries_node(state: RouterState) -> RouterState:\n",
        "    \"\"\"\n",
        "    Processes grocery delivery requests with driver pickup service\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a grocery delivery assistant for a service where our drivers pick up groceries for customers.\n",
        "\n",
        "    Based on the user's request, organize the following information:\n",
        "\n",
        "    Shopping List:\n",
        "    - List of grocery items needed\n",
        "    - Quantities or amounts for each item\n",
        "    - Brand preferences (if mentioned)\n",
        "    - Any dietary restrictions or organic preferences\n",
        "\n",
        "    Store Information:\n",
        "    - Preferred store or location\n",
        "    - Budget considerations\n",
        "    - Special instructions for finding items\n",
        "\n",
        "    Delivery Details:\n",
        "    - Delivery address (if provided)\n",
        "    - Preferred delivery time window\n",
        "    - Any special delivery instructions\n",
        "    - Contact information for driver coordination\n",
        "\n",
        "    Driver Instructions:\n",
        "    - Substitution preferences (if item unavailable)\n",
        "    - How to handle out-of-stock items\n",
        "    - Any items requiring special handling (fragile, cold items)\n",
        "    - Payment method (if mentioned)\n",
        "\n",
        "    User Request: \"{state['user_input']}\"\n",
        "\n",
        "    Provide a comprehensive delivery order summary that our driver can use to efficiently shop and deliver groceries.\n",
        "    Include estimated pickup time and any special notes for the shopping trip.\n",
        "\n",
        "    Format the response as a clear, organized delivery order that includes all necessary details for our driver service.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"task_type\": \"groceries\",\n",
        "        \"output\": response.content.strip()\n",
        "    }\n",
        "def default_handler_node(state: RouterState) -> RouterState:\n",
        "    prompt = f\"\"\"\n",
        "    I couldn't classify your request into a specific category.\n",
        "    Let me provide general assistance for: \"{state['user_input']}\"\n",
        "\n",
        "    I can help you with:\n",
        "    - Ride hailing services\n",
        "    -  Restaurant orders\n",
        "    -  Grocery shopping\n",
        "\n",
        "    Please rephrase your request to match one of these services, or if you need assistance with something else, I will connect you with our customer support team who can provide personalized help.\n",
        "\n",
        "    Would you like me to:\n",
        "    1. Help you rephrase your request for one of our services\n",
        "    2. Connect you with customer support for additional assistance\n",
        "    \"\"\"\n",
        "    response = llm.invoke(prompt)\n",
        "    return {**state, \"task_type\": \"default_handler\", \"output\": response.content.strip()}\n",
        "\n",
        "workflow = StateGraph(RouterState)\n",
        "workflow.add_node(\"ride_hailing_call\", ride_hailing_node)\n",
        "workflow.add_node(\"restaurant_order\", restaurant_order_node)\n",
        "workflow.add_node(\"groceries\", groceries_node)\n",
        "workflow.add_node(\"default_handler\", default_handler_node)\n",
        "workflow.add_node(\"router\", router_node)\n",
        "workflow.set_entry_point(\"router\")\n",
        "# Update your conditional edges to route to all three options\n",
        "workflow.add_conditional_edges(\"router\", router, {\"groceries\":\"groceries\", \"restaurant_order\":\"restaurant_order\",\"ride_hailing_call\":\"ride_hailing_call\",\"default_handler\":\"default_handler\"})\n",
        "\n",
        "\n",
        "# Set all three as possible finish points\n",
        "\n",
        "workflow.set_finish_point(\"ride_hailing_call\")\n",
        "workflow.set_finish_point(\"restaurant_order\")\n",
        "workflow.set_finish_point(\"groceries\")\n",
        "\n",
        "app = workflow.compile()\n",
        "\n",
        "test_cases = [\n",
        "    {\"user_input\": \"I need a ride from downtown to the airport at 3pm\"},\n",
        "    {\"user_input\": \"I want to order 2 large pepperoni pizzas for delivery\"},\n",
        "    {\"user_input\": \"I need milk, bread, eggs, and vegetables for the week\"},\n",
        "    {\"user_input\": \"What's the weather like today?\"},  # Default/unclassified example\n",
        "]\n",
        "\n",
        "for i, test_input in enumerate(test_cases, 1):\n",
        "    result=app.invoke(test_input)\n",
        "\n",
        "\n",
        "    print(f\"question {test_input['user_input']}\\n\")\n",
        "    print(f\"task_type {result['task_type']}\\n\")\n",
        "    print(f\"output: {result['output']}\\n\")\n",
        "    print('-----------------------------------')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".conda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "prev_pub_hash": "af2f53da5f34d69c384ef6f644fe5a7bc7c06928f1e87aaad2cfd992a92045cf"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
